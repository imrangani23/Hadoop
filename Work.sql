***************************************
-- <INSTALLATION..UPGRADATIONFIXPACK=>
***************************************

BEGIN

#installation #upgradation #migration #fixpack #fp
--FRESH INSTALLATION 
'Checking installation prerequisites' #prereqcheck

	./db2prereqcheck -v 10.5.0.0  -o output_file

	-c for client installation, -s validation summary only, -v  to check whether the prerequisites are met for DB2 Version 10.5, -i is fornon-DB2 pureScale prerequisites only.
	
'Disk Requirements'
	/tmp space 
	  DB2 pureScale® environment is 2 GB
	  Non Purescale is 512 MB. 	
	
	/var directory requires 512 MB.
	/home - 1 to 1.5 GB required

On Windows: 
	40 MB in the system drive
	60 MB in the temporary folder 
	
'Memory Requirements' 
	DB2 database system - 256 MB RAM
	DB2 and the DB2 GUI tools and HP-UX Version requries - 512 MB RAM 
	DB2 client - additional 16 MB of RAM per five client connections.
	
 minimum swap/paging space configuration for most systems is 25-50% of RAM

'DB2 users and groups (Linux and UNIX)'
	Instance ID - db2inst1:db2iadm1 - controls all DB2 processes and owns all filesystems and devices used by the databases contained within the instance.
	Fenced ID - db2fenc1:db2fadm1 - to run user defined functions (UDFs) and stored procedures outside of the address space used by the DB2 database.
	DB2 Admin server ID - dasusr1 - deprecated in 9.7.

'OS user limit requirements' for instance user
	data - unlimited (Maximum private memory allowed for a process)
	nofile - 65536 (Maximum number of open files allowed for a process)
	fsize - UNLIMITED (Maximum file size allowed)

	Values for ulimits must be set manually, except on AIX® operating systems, where you can set ulimits by running the db2rfe command.

'Kernal Parameters'
	Updated by default.Incase if you want to edit ->
	
	"ipcs -l" command to list the current kernel parameter settings.

	edit the "/etc/sysctl.conf" to change kernal settings.
	Run "sysctl -p" parameter to load in sysctl settings from the default file /etc/sysctl.conf
	
--	IPC kernel parameter		Enforced minimum setting
	kernel.shmmni (SHMMNI)		256 * <size of RAM in GB>
	kernel.shmmax (SHMMAX)		<size of RAM in bytes>1
	kernel.shmall (SHMALL)		2 * <size of RAM in the default system page size>2
	kernel.sem (SEMMNI)			256 * <size of RAM in GB>
	kernel.sem (SEMMSL)			250
	kernel.sem (SEMMNS)			256 000
	kernel.sem (SEMOPM)			32
	kernel.msgmni (MSGMNI)		1 024 * <size of RAM in GB>
	kernel.msgmax (MSGMAX)		65 536
	kernel.msgmnb (MSGMNB)		65 536 

************************************************************************************************************
--'INSTALLING A FIXPACK'
Stopping all the process before/afeter clean shutdown 

	"su - iname
	. $HOME/sqllib/db2profile
	db2 force applications all
	db2 terminate
	db2stop
	db2licd -endd      # run at each physical partition
	exit
	"
If das user enabled and running ->
	"su - aname
	. $HOME/das/dasprofile
	db2admin stop
	exit"

On AIX to unload unused shared libraries from memory before installation
	
	"/usr/sbin/slibclean" 
	
To stop the Fault Monitor Daemon
 
	"DB2DIR/bin/db2fm -i iname -D"

Fault Monitor Coordinator (FMC) is started, prevent your instances from auto-starting:

	"DB2DIR/bin/db2fmcu"
		 If the FMC is disabled, the output from the db2fmcu command will be: FMC: down.
If FMC is started -> 
	"DB2DIR/instance/db2iset -i iname -all"
	-> the resulted instances from the above cmd are configured to auto-start:DB2AUTOSTART=YES	
To prevent from auto-starting 
	"DB2DIR/instance/db2iauto -off iname"
	
To stop DB2 interprocess communications->
	"$HOME/sqllib/bin/ipclean"

++++++++++++++++++++++++++++++++++++++++++++++++

'If issues comes in the middle of FixPack installation' #fixpack #installation #errors #issues
	
Trying to stop or kill this process is quite a task, and varies by operating system. Instead, try the force option with the installFixPack command.

	Sometimes - Installation step will fail at "Preparing the system :.......Failure" -> the db2 lib file loaded with any of the agent -> at that time we need to verify and install using -f db2lib option

	with root you can run db2prereq as below 

"	     <INSTALL_PATH>/instance/db2prechk -b /opt/ibm/db2/V9.7 -d;echo $?         "

	Iff 0 is returned then no db2 libraries were found.
	You can workaround the issue by running the installFixpack with -f db2lib option

	Iff 1 is returned then you will also see in the list generated by db2prechk the libraries that are 'IN USE'

	Similar to the following
	/opt/ibm/db2/V9.7/lib32/libdb2locale.so: NOT IN USE  
	/opt/ibm/db2/V9.7/lib32/libdb2locale.so.1: NOT IN USE  
	/opt/ibm/db2/V9.7/lib32/libdb2osse_db2.so: NOT IN USE  
	/opt/ibm/db2/V9.7/lib32/libdb2osse_db2.so.1: NOT IN USE  
	/opt/ibm/db2/V9.7/lib32/libdb2osse.so: NOT IN USE  
	/opt/ibm/db2/V9.7/lib32/libdb2osse.so.1: NOT IN USE  
	/opt/ibm/db2/V9.7/lib64/libdb2locale.so: IN USE  


	On AIX -> " /usr/bin/genld -l | grep -p db2 "

		Clean up the above processes and rerun the db2prechk command to verify that it returns 0.

		Then retry the normal installFixPack command. Iff it still fails with the same error and there are no libraries loaded per the db2prechk output then you can run the installFixpack with the -f db2lib command to bypass the library check.

		   " ./installFixPack -f db2lib -b /db2/code/V101 "

'After installing a fix pack'

"db2iupdt" -> Certain executables or components are installed or removed, existing instances do not automatically inherit the new system configuration parameters or 			   gain access to all the additional function. The instance must be updated
				db2iupdt command updates/Replaces the files in the INSTHOME/sqllib directory.
				It overwrites the db2profile and db2cshrc scripts. It does not overwrite the userprofile and usercshrc scripts.
					"DB2DIR/instance/db2iupdt iname"
				
"db2iupdv105" -> Update the system catalog objects in your databases to support the fix pack.
				as instance owner "db2updv105 -d dbname"
	Note: Backup your database before running db2updv105. Some system objects might become unusable after moving back to an earlier fix pack, and your database will need to be restored.
	
"Bind the bind files" -> 

	cd $HOME/sqllib/bnd
	db2 "bind db2schema.bnd BLOCKING ALL GRANT PUBLIC sqlerror continue"
	db2 "bind @db2ubind.lst BLOCKING ALL GRANT PUBLIC sqlerror continue"
	db2 "bind @db2cli.lst BLOCKING ALL GRANT PUBLIC sqlerror continue"
	
	After you install a fix pack, some packages are marked as invalid. Packages marked as invalid are implicitly rebound the first time an application uses them. To eliminate this overhead and to ensure that the rebind is successful, manually rebind all packages. For example, issue the db2rbind command:
	
	"db2rbind <dbname> -l /tmp/db2rbind_<dbname>.log all"

'Revalidating objects: DB2 System packages might fail during rebind with SQL2453N error'

This happens especially after upgrading the database from different release.

In order to revalidate these invalid system packages you can use: 

	db2 "CALL SYSPROC.ADMIN_REVALIDATE_DB_OBJECTS(NULL, 'SYSIBMADM', NULL)" 

'Rebinding packages in DB2 V10.1 fails with SQLCODE -551 '

		http://www-01.ibm.com/support/docview.wss?uid=swg21588835  <- refer link 


		http://db2forum.wordpress.com/ 

'Uninstalling fix packs'

	"./installFixPack -f level -b DB2DIR"
-f level is to bypass the level check incase of falling back to older FP level.
************************************************************************************************************
--Upgradation

--'Pre-Upgrade tasks'
	1. Backup entire database.
	2. Backing up DB2 server configuration:  "db2support output-directory -d database-name -cl 0" (db2support -preupgrade)
		-cl 0 parameter collects the database system catalog, database and database manager configuration parameters settings, DB2 registry variables settings and place in db2support.zip file.
	3. db2 "LIST PACKAGES FOR ALL/SCHEMA schema-name SHOW DETAIL"	> /upgrade/sample_pckg.txt
	4. db2audit describe > audit_instance-name.cfg
	5. Backing up all external routines. 
		cp -R $INSTHOME/sqllib/function $INSTHOME/routine_backup
	6.   db2 GET DBM CFG > dbm_instname.cfg
	7. db2 GET DB CFG FOR database_alias SHOW DETAIL > db_database_alias.cfg
	8. db2look -d sample -e -o sample_tbs.db2 -l -x
	9. db2set -all > reg_instname.txt
   10. set |grep DB2 > env_instname.txt
   
   Points 6 to 9 is optional since all details will be available in point 2.

   11. Gathering pre-upgrade diagnostic information Version 10.5.0 - "db2fodc -preupgade and db2support -preupgrade"
		it collects performance related information that might be needed for future problems
		
'Disk space requirements' 
	1. Increasing the total size to twice the total size of the system catalog table space is recommended for System catalog table space (SYSCATSPACE) and Temporary table space (TEMPSPACE1 is the default name).
	2. Increaase log file space - logsecond and logprimary
	3. Index space 

 --'Upgrade steps for DB2 servers'
 
1.Instance upgrade - "db2iupgrade -u fenced_id instance_name"
	calls the db2ckupgrade command
	Upgrades an existing instance to a new instance under a DB2 Version 10.5 copy
	Upgrades instance profile registry variables (not the user.s global registry profile variables)
	Upgrades the database manager configuration file.
	Sets the jdk_path database manager configuration parameter.
 
 Before you beginn 
	- 5 GB of free space in the /tmp directory.
	- Run db2ckupgrade  before exe. db2iupgrade.
	- Running the db2iupgrade or the db2icrt command for a root user is not supported.

"db2ckupgrade dbaname (or) -e" - In a partitioned database environment, the db2ckupgrade command will check each database partition.
		-e is for all dbs to be scanned for upgrade and -l option is for log files.
	path for db2ckupgrade DB2DIR/bin directory.
	
	It verifies 
	- the mentioned db name is available in te catalog.
	- A database is not in inconsistent, backup, restore, rollforward, load, redistribute pending states. 
	- Table spaces are in a normal state.
	- HADR database role is not standby
	
	The default log file created for db2iupgrade is /tmp/db2ckupgrade.log.processID and also a upgrade.log will get created in instance home directory.

'Procedure:' 
		Force all users - db2 list applications; db2 force application all; db2 terminate; db2stop
		As Root user - $DB2DIR/instance/db2iupgrade [ -u fencedID ] InstName
		As instance user - db2start;db2level 
		

2. Database upgrade - "UPGRADE DATABASE command" -  database upgrade process makes changes to system catalog objects in a single transaction (need adequate log space )
	The following database entities might be converted during the database upgrade:
		
	- Database configuration file
	- Log file header
	- Global log file header file
	- Table root page for all tables
	- Index root page for all tables
	- Catalog tables
	- Storage group files
	- Buffer pool files
	- Table space files
	- History file
	- Renames all the log files in the active log path with the extension .MIG. After you upgrade your databases successfully, you can delete all the S*.MIG files.
	- Automatically collects statistics for all system catalog tables during database upgrade

	
	For upgrade database commands fails - refer the link https://www.ibm.com/support/knowledgecenter/en/SSEPGG_10.5.0/com.ibm.db2.luw.qb.upgrade.doc/doc/t0007193.html?pos=2
	
************************************************************************************************************
'To List Packages available in DB2 installed version:'

	/opt/IBM/db2/V10.5/install/db2ls -q >>>>> To list the features of the db2 installed
	/opt/IBM/db2/V10.5/install/db2ls -q -p >>>>> To list the product description
	db2licm -l >>>>> To list liscence details

'How could you know the version of a DB2 Java driver?'

	C:\Program Files\IBM\SQLLIB\java>java com.ibm.db2.jcc.DB2Jcc -version

	
Below link is useful for db2 upgrades.

http://www-01.ibm.com/support/docview.wss?rs=71&context=SSEPGG&uid=swg21200005

END

*******************************
-- < INSTANCE LEVEL COMMANDS =>
*******************************

BEGIN


<' To kill all the process owned by an instance owner '>

	$ ps -ef | grep <db2inst1> | awk '{print "kill -9 "$2}' > /tmp/kpid 
 
 
<' To find out the amount of instance shared memory used by the database partition, use the DB2 memory tracker tool, db2mtrk:'>

	db2mtrk –i –v

For 'SQL1032N error'

	sysctl -w kernel.shmmax=268435456 --> system error while starting db2

	DB2_FMP_COMM_HEAPSZ=12000

'SSL Configuration:'
********************

Need GSkit to confiure SSL in db2 -> from 10.5 the GSkit installed along with DB2 and available in sqllib/lib64/gskit if not available need to install GSkit separately.

	GSK version information:
	->lslpp -l | grep -i gsk
	GSKit8.gskcrypt32.ppc.rte
	8.0.14.43 COMMITTED IBM GSKit Cryptography Runtime
	GSKit8.gskcrypt64.ppc.rte
	8.0.14.43 COMMITTED IBM GSKit Cryptography Runtime
	GSKit8.gskssl32.ppc.rte 8.0.14.43 COMMITTED IBM GSKit SSL Runtime With
	GSKit8.gskssl64.ppc.rte 8.0.14.43 COMMITTED IBM GSKit SSL Runtime With
	gskjs.rte 7.0.3.18 COMMITTED AIX Certificate and SSL Java
	gskjt.rte 7.0.3.18 COMMITTED AIX Certificate and SSL Java
	gsksa.rte 7.0.4.48 COMMITTED AIX Certificate and SSL Base
	gskta.rte 7.0.4.48 COMMITTED AIX Certificate and SSL Base
	mqm.gskit.rte 8.0.0.5 COMMITTED IBM Global Security Kit for

	env variable LIBPATH should set to $INSTHOME/sqllib/lib64/gskit

<" Client Side setup "> - Provided the Certificate issued by CA. 

Part 1:

	Place the certificate in a path -> home/db2msg01/certs/SSL-Certs/Development/DigiCertGlobalRootCA.crt (*.crt is the cerficate issued by the clients)

Part 2:

	command to create the stash:

		"gsk8capicmd -keydb -create -db /home/db2msg01/certs/db2keys.kdb -pw db2passwd -type kdb -expire 3650 -stash"

		-db -> we can name the .kdb filename and -pw as our wish. The -stash option creates a stash file at the same path as the key database, 
		with a file extension of .sth. At connect time, GSKit uses the stash file to obtain the password to the key database.

	NA340680-SAL:db2msg01:db2msg01:/home/db2msg01/certs
	->ls -lrt
	total 64
	drwxr-xr-x 4 db2msg01 mqm 256 Sep 27 15:04SSL-Certs
	-rw-rw---- 1 db2msg01 mqm 129 Oct 10 12:44db2keys.sth
	-rw-rw---- 1 db2msg01 mqm 88 Oct 10 12:44db2keys.rdb
	-rw-rw---- 1 db2msg01 mqm 88 Oct 10 12:44db2keys.crl
	-rw-rw---- 1 db2msg01 mqm 5088 Oct 10 12:45db2keys.kdb

	note: *.kdb contains certificates information. *.rdb contains certificate request information. *.crl is no longer used now. *.sth is called stash file, it contains an encrypted
	version of key database password.

Part 3: 

	Add the signer certificate into the client key database:

	Command to add cert

		" gsk8capicmd -cert -add -db "/home/db2msg01/certs/db2keys.kdb" -pw db2passwd -label db2devkey -file /home/db2msg01/certs/SSL-Certs/Development/DigiCertGlobalRootCA.crt "

			-db, -pw -> is same as we mention in Part 2. 
			-label -> convinient name to identify the cert - we can set as per our wish
			-file -> is the path/filename as mentioned in Part 1.

	The below command will list the added keys:

		" gsk8capicmd -cert -list -db "/home/db2msg01/certs/db2keys.kdb" -pw db2passwd "

	Example:
	->NA340680-SAL:db2msg01:db2msg01:/home/db2msg01/certs
	->gsk8capicmd_64 -cert -list -db "/home/db2msg01/certs/db2keys.kdb" -pw db2passwd
	->Certificates found
	->* default, - personal, ! trusted, # secret key
	->! db2qakey


With the above 3 Parts -> the 1st half of SSL configuration with the gsk commands completed - 2nd half needs to be done by DBA - explained the steps below

	For CLP and embedded SQL clients: 
		
		db2 "catalog TCPIP NODE mynode REMOTE 127.0.0.1 SERVER 50001 SECURITY SSL "

		db2 "catalog DATABASE sample AS myssldb AT NODE mynode AUTHENTICATION SERVER"


		db2 update dbm cfg using 
		SSL_CLNT_KEYDB /home/test1/sqllib/security/keystore/clientkey.kdb 
		SSL_CLNT_STASH /home/test1/sqllib/security/keystore/clientstore.sth

		db2 connect to myssldb user user1 using password

-> CLI/ODBC client applications:(If you are using the IBM data server client or IBM Data Server Runtime Client - edit the db2cli.ini file in $HOME/sqllib/cfg as below) permission of db2cli.ini file should be 775

	[sampledb]
	Database=sampledb
	Protocol=tcpip
	Hostname=myhost
	Servicename=50001
	Security=ssl
	SSL_client_keystoredb=/home/test1/keystore/clientstore.kdb
	SSL_client_keystash=/home/test1/keystore/clientstore.sth

-> Edit the ODBC file as follows: (the file path we need to check whomso installed the odbc drivers)
	[BLUDB]
	DRIVER=/home/db2msg01/sqllib/lib64/db2o.o
	UID=inpiibdv
	AUTHENTICATION=SERVER
	PORT=50001
	HOSTNAME=dashdb-enterprise4-yp-delhaize-01.services.dal.bluemix.net
	PROTOCOL=TCPIP
	DATABASE=BLUDB
	SSLCertFile = /home/db2msg01/certs/db2keys.kdb 

Detailed Documentation available in <- https://www.ibm.com/support/knowledgecenter/SSEPGG_10.1.0/com.ibm.db2.luw.admin.sec.doc/doc/t0053518.html

************************************************************
<" Server Side setup: ">

	export LIBPATH=/opt/db2home/tlogdev/sqllib/lib64
	export PATH=$PATH:/usr/opt/ibm/gsk8_64/bin

	gsk8capicmd_64 -keydb -create -db "na041400.kdb" -pw "zn%e7A5H" -stash
	gsk8capicmd_64 -cert -create -db "na041400.kdb" -pw "zn%e7A5H" -label "CognosSSL" -dn "CN=na041400-sal.delhaize.com,O=DELHAIZE,OU=InfoGen1,L=Salisbury,ST=NC,C=USA"
	gsk8capicmd_64 -cert -extract -db "na041400.kdb" -pw "zn%e7A5H" -label "CognosSSL" -target "na041400.arm" -format ascii -fips

	db2 update dbm cfg using SSL_SVR_KEYDB /opt/db2home/tlogdev/SSL/na041400.kdb
	db2 update dbm cfg using SSL_SVR_STASH /opt/db2home/tlogdev/SSL/na041400.sth
	db2 update dbm cfg using SSL_SVR_LABEL CognosSSL
	db2 update dbm cfg using SSL_SVCENAME 60092

	db2set DB2COMM=SSL,TCPIP

	db2 update dbm cfg using DIAGLEVEL 4

	END

***********************************************
-- < DATABASE PARTITIONS  #DPF #DBPARTITIONS =>
***********************************************
https://books.google.co.in/books?id=0Qu5AQAAQBAJ&pg=PA71&lpg=PA71&dq=Distribution+maps+db2&source=bl&ots=v51tEYe5Ty&sig=zikYt9fZkFlAnAZVkroqFo0rJBs&hl=en&sa=X&ved=0ahUKEwje8fOy6bLSAhUJS7wKHVmyASgQ6AEILDAE#v=onepage&q=Distribution%20maps%20db2&f=true


BEGIN

'Supported operating systems'
	AIX, Linux, HP-UX, Solaris and Windows.
	
'Minimum memory requirements'
	DB2 database system - 256 MB RAM
	DB2 and the DB2 GUI tools and HP-UX Version requries - 512 MB RAM 
	DB2 client - additional 16 MB of RAM per five client connections.
	
'Deciding on the number of database partitions'
	Supports maximum of 1000 partitions.
		Consider: 
			1. The total amount of data under each partition - should not too high 
			2. The amount of CPU, memory, and disk available - minimum of 1 CPU needs to be available per db partition
			3. Workload Type - OLTP {large numbers of active sessions, simple SQL statements to process, and single row updates,query needs to completes in seconds} or                    DSS {small numbers of large and complex query statements, fewer transactions updating records as compared to transactions reading 					 records, and many sequential I/O operations}
			4. Logging - logs are created per partition Log management increases as the number of partitions increase, for example, archiving and retrieving log files
			
'Logical and physical database partitions'
	Large "SYMMETRIC MULTIPROCESSOR (SMP) MACHINE" - consider implementing a shared everything configuration and using logical database partitions. 
	Multiple physical machines are available, such as a "MASSIVELY PARALLEL PROCESSING (MPP)" configuration, consider using a shared nothing architecture and physical
    partitions. 
	"MULTIPLE PHYSICAL SMP MACHINES", consider using both physical and logical partitions.

	
'Partition group' -  is a collection of one or more database partitions. 
	By Default every db has - IBMCATGROUP which has syscatspace tablespace. 
								IBMDEFAULTGROUP which has userspace1. 
									IBMTEMPGROUP which has the tempspace1. 
	
	All the 3 Partition groups can not be alter or Dropped. 
	
	OLPT - type workload data into partition groups that span one partition. 
	DSS  - type workload data and large tables placed across multiple partitions.
 	
Command:	
	db2 "CREATE DATABASE PARTITION GROUP <GROUP-NAME> ON ALL DBPARTITIONNUMS"
	db2 "CREATE DATABASE PARTITION GROUP <GROUP-NAME> ON  DBPARTITIONNUMS(2,3)"
    db2 "ALTER/DROP/LIST DATABASE PARTITION GROUP"  NOTE: IBMTEMPGROUP never listed.
	
'Distribution maps and distribution keys'
	Each partition group has a distribution map that is created when the partition group is created. The distribution map is used by the database manager to find the data
	
	single-partition database partition groups - 1 entry in Distribution map
	multiple-partition database partition groups - 32768 wide array in DISTRIBUTION map.
	
	When a row is inserted into a table, DB2 uses a hashing algorithm on the distribution key to determine on which partition to store the row of data by using the distribution map
	
	'How to find the Distribution Key for an Existing Table'
	
		Here is a SQL that could be used to find distribution key for an existing table. Just substitute the table name with the one that you are interested in.
		db2 "select tabschema, tabname, colname, partkeyseq from syscat.columns where tabname like 'TRANSACTION%' and partkeyseq !=0 order by partkeyseq with ur"
		
"Selecting distribution keys" 
	1. Frequently joined columns
	2. Integer columns are more efficient than character columns. 
	3. Equijoin columns and small no. of columns 
	4. Columns that have a high proportion of different values to ensure an even distribution of rows across all database partitions in the database partition group.
	
'Collocation'
	
	Collacation is the placement of rows from different tables that contain related data in the same database partition group.
	 Collocated tables help the database manager to use more efficient join strategies.
	  Tables are considered to be collocated if they are in a multiple partition database partition group, have the same number of columns in the distribution key, and  if the data types of corresponding columns are compatible. 
		 Rows in collocated tables with the same distribution key value are placed on the same database partition. 
		  Tables can be in separate table spaces in the same database partition group, and still be considered collocated.
		
'CATALOG PARTITION'
	CATALOG Partition is the partition where the system catalog tables are created. 
	The catalog partition is created on the partition "where the CREATE DATABASE statement is issued".
	
'COORDINATOR PARTITION'
	User interaction occurs through one database partition, known as the coordinator partition for that user.
	The coordinator partition runs on the same database partition aas the application, or in the caase of a remote application, the database partition to which that application is connected. 
	Any database partition can be used as a coordinator partition.
	The application can use the "SET CURRENT CLIENT" statement to specify to which database partition to connect.
	
'TABLE JOINs IN DPF'
	Collocated joins - 
	
	
	
	
	
	
	
<' To find/count how many nodes are there in a dpf database '>

	dbn=`db2 -x "SELECT count(distinct host_name) FROM TABLE(DB_PARTITIONS())"`

	<Example>
	    tsmoks=`rah db2adutl query full db ${DBNAME} owner dssprod | grep 'completed ok' | wc -l`

	Both the values should be equal -> easy way to measure whether the tsm works for all the nodes.


	integer dbp=`db2 -x "SELECT count(*) FROM TABLE(DB_PARTITIONS())"`

***********************************************************************************************
'	DB2 DPF rollforward with overflow log path'
	
	To apply the logs that you have extracted from your partitioned restore (using the LOG TARGET parameter), 
	During a DPF restore you can specify the LOG TARGET in the individual partition restore commands (Example: /test_backup/test_restore_logs) and thenn use those paths for your rollforward command at the end.  Here is a simple example of a rollforward command for a simple 9 partition (catalog + 8 data partitions) environment with individual paths for each partitions respective logs:
	 
	db2 "rollforward db test to end of backup on all
	dbpartitionnums overflow log path (
	/test_backup/test_restore_logs/NODE0000,
	/test_backup/test_restore_logs/NODE0001 on dbpartitionnum 1,
	/test_backup/test_restore_logs/NODE0002 on dbpartitionnum 2,
	/test_backup/test_restore_logs/NODE0003 on dbpartitionnum 3,
	/test_backup/test_restore_logs/NODE0004 on dbpartitionnum 4,
	/test_backup/test_restore_logs/NODE0005 on dbpartitionnum 5,
	/test_backup/test_restore_logs/NODE0006 on dbpartitionnum 6,
	/test_backup/test_restore_logs/NODE0007 on dbpartitionnum 7,
	/test_backup/test_restore_logs/NODE0010 on dbpartitionnum 8)"
	 
	END
	
***********************************************
--< BUFFERPOOLS.. BP => #bufferpools #buff #bp
*********************************************** 

BEGIN

<' To Find out the bufferpool Hitratio '>

	db2 -x "SELECT Substr(db_name,1,10) as DB_NAME, SUBSTR(BP_NAME,1,20) as BP_NAME,TOTAL_HIT_RATIO_PERCENT as ALL_HR,DATA_HIT_RATIO_PERCENT as DATA_HR, 	INDEX_HIT_RATIO_PERCENT as INX_HR, SNAPSHOT_TIMESTAMP FROM SYSIBMADM.BP_HITRATIO Where BP_NAME not like 'IBMSYS%' with ur" 


<'Buffer Pool Hit Ratio: BPHR (%)'> 

	It indicates the % of time that the dbm didn’t need to load a page from disk to service a page request that is page is already in the buffer pool. The > BP ratio lowers the frequency of disk I/O

	BPHR = (1 - (("Buffer pool data physical reads" + "Buffer pool index physical reads") / ("Buffer pool data logical reads" + "Buffer pool index logical reads"))) * 100

<' Package Cache Hit Ratio (PCHR):'> 

	The package cache sets the amount of database global memory to be used for caching a packages static and dynamic SQL statements. 
	The package cache is used for caching sections for static and dynamic SQL statements. 
	The Package Cache Hit Ratio (PCHR) should be as close to 100% as possible without taking needed memory away from buffer pools

	PCHR = ( 1-("Package Cache Inserts / Package Cache Lookups"))*100


	Package Cache Inserts: When a new package section is compiled and inserted into the cache i.e., package cache insert count is incremented.


	Package Cache Lookups:When a request for a package is made and a lookup is performed check if this is already available in the cache so, the value is incremented, 
	whether or not a package in the cache satisfies the request substituting the values.

	The good hit ratio should be above 95%. A smaller hit ratio indicates that the pckcache_sz parameter should be increased in the db cfg parameters

<'Catalog cache hit ratio (CCHR):'> 

	The catalog cache is used to store table descriptor information that is used when the tables, views, or alias have been referenced in previous statements.
	This element includes both successful and unsuccessful accesses to the catalog cache. The catalog cache is referenced whenever:

	A table, view, or alias name is processed during the compilation of an SQL statement.
	Database authorization information is accessed
	A routine is processed during the compilation of an SQL statement

	CCHR = (1-(Catalog cache inserts / Catalog cache lookups))*100


	Catalog cache inserts:Number of times that the system tried to insert table descriptor information into the catalog cache.

	Catalog cache lookups: Number of times that the catalog cache was referenced to obtain table descriptor Information. 
	The hit ratio above 95%, it can be taken aas a good hit ratio. A smaller hit ratio is the indication that the catalogcache_sz should be increased.


END

***********************************
--< DATABASE..DATABASELEVEL..DB =>
***********************************

BEGIN

< ' How to catalog a DB2 Database '>

	set the db2comm resistry variable to tcpip -> db2set db2comm=tcpip
	set the dbm cfg parameter SVCENAME to db2service name/port no

		" telnet <server_name> <port_number> "-> to check the server is pingable

	To add new db catalog that connect to remote server use:"
		DB2 CATALOG TCPIP NODE <remotenode> REMOTE <server-ip.address> SERVER <port>
		DB2 CATALOG DATABASE <dbname> AS <dbname.alias> AT NODE <remotenode> {AUTHENTICATION DATA_ENCRYPT}
"
	Replace <remotenode> with name of remote node, <server-ip.address> with remote server ip address, <port> with connection port, <dbname> with database name, <dbname.alias> with database alias.

	To remove the catalogged database:"

		db2 uncatalog db <dbname>
		db2 uncatalog node <nodename>
"
	<! Forr errors : refer link ( http://www-01.ibm.com/support/docview.wss?uid=swg21164785) 

	db2 "catalog admin local node <mynode2> instance <linges> SYSTEM <oc2583011063.ibm.com> OSTYPE <LINUX>"

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
	
<' To Find the size of database '> #dbsize #size

		echo "---------------------------------------------------------------------------------";
		echo "HOSTNAME INSTANCE DBNAME DB_SIZE_IN_GB TOTAL_DB_CAPACITY_IN_GB" ;
		echo "---------------------------------------------------------------------------------";
		for i in `db2 list db directory|sed -e '/./{H;$!d;}' -e 'x;/Indirect/!d'|grep -i alias|awk '{print $4}'`; 
		do
		db2 connect to $i > /dev/null;
		db2 -x "select '`hostname`', '`whoami`', '$i', decimal(float(decimal(float((DB_SIZE/1024)/1024),9,2)/1024),9,2) as DB_SIZE_IN_MB, \
		decimal(float(decimal(float((DB_CAPACITY/1024)/1024),9,2)/1024),9,2) as DB_CAPACITY_IN_MB from systools.STMG_DBSIZE_INFO";
		db2 terminate > /dev/null; done; 
		echo "---------------------------------------------------------------------------------" 


	>>-GET_DBSIZE_INFO--(--snapshot-timestamp--,--dbsize--,--------->

	>--dbcapacity--,--refresh-window--)---------------------------->

		< EXample >: db2 "CALL GET_DBSIZE_INFO(?, ?, ?, -1)"

and

		db2 "select SNAPSHOT_TIMESTAMP,DB_SIZE,DB_CAPACITY from SYSTOOLS.STMG_DBSIZE_INFO" 

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

<' Quiesce the database to disable external connection to database except dbadmins '>

	db2 connect to <dbname>
	db2 QUIESCE DATABASE IMMEDIATE FORCE CONNECTIONS
	db2 connect reset

'Unquiesce the database'

	db2 connect to <dbname>
	db2 unquiesce db
	db2 connect reset

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
' DBPATHS administrative view '
 
To find out the paths involved in DB2 

	db2 "select dbpartitionnum, substr(type,1,20) as type, path from sysibmadm.dbpaths"

(OR)

	db2 "SELECT DBPARTITIONNUM, TYPE, PATH FROM TABLE(ADMIN_LIST_DB_PATHS()) AS FILES"

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

END
END

*****************************************
--<" DB and DBM cgf settings details" =>
*****************************************

BEGIN
<' STMM - Self Tuning Memory '> 
 
DBM CFG Parameter - " self_tuning_mem " 

Configuration parameters that can be automatically tuned when STMM ON.

	database_memory - Database shared memory size
	locklist - Maximum storage for lock list
	maxlocks - Maximum percent of lock list before escalation
	pckcachesz - Package cache size
	sheapthres_shr - Sort heap threshold for shared sorts
	sortheap - Sort heap size

To view the self tuning settings for memory consumers controlled by configuration parameters 

- use the GET DATABASE CONFIGURATION command specifying the SHOW DETAIL parameter.

To view the self tuning settings for buffer pools, use one of the following methods. 

	- db2 "SELECT BPNAME, NPAGES FROM SYSCAT.BUFFERPOOLS"
		the NPAGES field in the SYSCAT.BUFFERPOOLS catalog view for that particular buffer pool will be set to -2. When self tuning is disabled, the NPAGES field will be set to the buffer pool's' current size.
		
	- db2 "GET SNAPSHOT FOR BUFFERPOOLS ON DB_NAME" 
		and examine the current size of the buffer pool (the value of the bp_cur_buffsz monitor element)

	'Using self-tuning memory in partitioned database environments'

To determine which database partition is currently specified as the tuning partition, call the ADMIN_CMD procedure as follows:

	" CALL SYSPROC.ADMIN_CMD('get stmm tuning dbpartitionnum') "

To change the tuning partition, call the ADMIN_CMD procedure as follows:

	" CALL SYSPROC.ADMIN_CMD('update stmm tuning dbpartitionnum <partitionnum>') "

Reference - Self-tuning memory overview -> http://www.ibm.com/support/knowledgecenter/en/SSEPGG_9.5.0/com.ibm.db2.luw.admin.perf.doc/doc/c0024366.html

<' Sort heap considerations '>


sheapthres_shr - Sort heap threshold for shared sorts DB configuration parameter/ Configurable online / Immediate / 4KB pages

"Shared sort memory model" - heapthres = 0 (The shared sort memory model is the only model where STMM tuning of sortheap and sheapthres_shr can occur)
For self tuning 
 
                  "SELF_TUNING_MEM=ON / sheapthres is set to 0 / sortheap = AUTOMATIC / DB2_WORKLOAD=analytics is not set "

"Private sort memory model" - sheapthres is not equal to zero / No STMM sort-tuning takes place under this model.

"Hybrid sort memory model" - sheapthres is not equal to zero, but the configuration dictates that shared sort memory is made available for certain operations / No STMM sort-tuning takes place.

NOTE: Self-tuning of the sheapthres_shr is not recommended with workloads that access column-organized tables, and is disabled when DB2_WORKLOAD=ANALYTICS 

#sortmonitoring:
	db2 "SELECT TOTAL_SECTION_SORT_PROC_TIME, TOTAL_SECTION_SORTS,TOTAL_SORTS, POST_THRESHOLD_SORTS, POST_SHRTHRESHOLD_SORTS, SORT_OVERFLOWS, \
	SORT_HEAP_ALLOCATED,SORT_SHRHEAP_TOP,POST_THRESHOLD_OLAP_FUNCS FROM TABLE (MON_GET_DATABASE(-2))"

#shared sort memory usage
	db2 "select memory_pool_used, memory_pool_used_hwm from table (mon_get_memory_pool(null,null,null)) where memory_pool_type='SHARED_SORT'"

<! DB2 UDB PRIVATE SORTING -> http://developeriq.in/articles/2011/sep/20/db2-udb-private-sorting/ 
-> http://etutorials.org/Misc/advanced+dba+certification+guide+and+reference/Chapter+8.+Performance+Tuning/Database+Configuration+Parameter+Tuning+and+Monitoring/ 


END

*********************************
--<" TABLESPACES..TBSP..TSPACE =>
*********************************

BEGIN

'Size of the tablespaces'

	db2 "select substr(TBSP_ID,1,5) as TBSP_ID, substr(TBSP_NAME,1,20) as TBSP_NAME,DBPARTITIONNUM , "TBSP_TYPE", TBSP_PAGE_SIZE / 1024 as TBSP_PAGE_SIZE_KB, TBSP_NUM_CONTAINERS, "TBSP_USED_PAGES", TBSP_USED_SIZE_KB / 1024 / 1024 as TBSP_USED_SIZE_GB ,TBSP_PAGE_TOP , TBSP_USING_AUTO_STORAGE, TBSP_AUTO_RESIZE_ENABLED from "SYSIBMADM"."TBSP_UTILIZATION" order by "TBSP_USED_PAGES" desc" > tbsp_util.out


'Size of tablespaces along with the size of the tables'

	db2 "select substr(a.tabname,1,40) as TABLE_NAME, a.TBSPACEID, substr(a.TBSPACE,1,20) as TBSP_NAME, b.TBSP_PAGE_SIZE / 1024 as TBSP_PAGE_SIZE_KB, b.TBSP_USED_PAGES, b.TBSP_USED_SIZE_KB / 1024 / 1024 as TBSP_USED_SIZE_GB, (a.fpages*TBSP_PAGE_SIZE/1024/1024/1024) as TABLE_SIZE_GB, a.card from syscat.tables a, sysibmadm.TBSP_UTILIZATION b where a.TBSPACEID=b.TBSP_ID order by "TABLE_SIZE_GB" desc with ur" | more 


	db2 "select substr(a.tabname,1,50) as TABLE_NAME,substr(a.tabschema,1,50) as TABLE_SCHEMA, a.TBSPACEID, substr(a.TBSPACE,1,20) as TBSP_NAME, (a.fpages*PAGESIZE/1024/1024/1024) as TABLE_SIZE_GB, a.card from syscat.tables a, syscat.tablespaces b where a.TBSPACEID=b.TBSPACEID and a.tabschema not like ('SYS%') order by "TABLE_SIZE_GB" , TBSP_NAME desc with ur" 


'To get table space state through MON_GET_TABLESPACE '> >>> #state #tbst #tablespacestate 

	db2 "select substr(tbsp_name,1,30) as tbsp_name, substr(TBSP_STATE,1,18) as TBSP_STATE from TABLE(MON_GET_TABLESPACE('',-2)) with ur"

'TO get HWM,free,used,total pages in a tablepsace' #tpspHWM #HWM
	
	freeSpaceBelowHWM = tbsp_free_pages - (tbsp_usable_pages - tbsp_page_top) 
	
	db2 "select TBSP_TOTAL_PAGES as Total_pages, TBSP_FREE_PAGES as Free_Pages,TBSP_USED_PAGES as Used_Pages,TBSP_PAGE_TOP as High_Water_Mark from table(mon_get_tablespace ('<USERSPACE1>', -1)) AS TBSP "  

'Checking table spaces for reclaimable storage'

	db2 "select substr(TBSP_NAME,1,14) as TS_NAME, TBSP_TOTAL_PAGES as Total_pages,TBSP_USED_PAGES as Used_pages,TBSP_FREE_PAGES as FREE_PAGES,TBSP_PAGE_TOP as High_water_MARK,reclaimable_space_enabled,TBSP_AUTO_RESIZE_ENABLED as AUTO_RESIZE,TBSP_USING_AUTO_STORAGE as AUTO_STORAGE from table (MON_GET_TABLESPACE (NULL , -1)) as ts where TBSP_NAME NOT LIKE ('SYS%') and TBSP_TYPE = 'DMS'"


# Reclaimable storage: Monitoring the processing:- <"MON_GET_EXTENT_MOVEMENT_STATUS ">

	db2 "SELECT varchar(tbsp_name,15) as tbsp_name, last_extent, num_extents_moved, num_extents_left, total_move_time from table (mon_get_extent_movement_status('tbspace',-1)) AS T"


'To check the tablespaces attained max size and TBSP utilization' 

	db2 " select substr(A.TBSP_NAME,1,15) TABLESPACE, substr(CONTAINER_NAME,1,40) CONTAINER , ((FS_TOTAL_SIZE_KB/(1024*1024))-(FS_USED_SIZE_KB/(1024*1024))) fs_free_space_GB , TBSP_UTILIZATION_PERCENT , TBSP_AUTO_RESIZE_ENABLED from sysibmadm.TBSP_UTILIZATION B , sysibmadm.CONTAINER_UTILIZATION A where TBSP_TYPE='DMS' and A.TBSP_NAME=B.TBSP_NAME and B.TBSP_UTILIZATION_PERCENT > 85"

	db2 " select substr(T1.TBSP_NAME,1,20) , substr(CONTAINER_NAME,1,45) , TBSP_UTILIZATION_PERCENT ,TBSP_AUTO_RESIZE_ENABLED from sysibmadm.TBSP_UTILIZATION T1 , sysibmadm.CONTAINER_UTILIZATION T2 where T1.TBSP_NAME= T2.TBSP_NAME and TBSP_UTILIZATION_PERCENT > '80' "

	db2 "select substr(TBSP_NAME,1,20) TBSP_NAME, TBSP_ID, TBSP_TOTAL_SIZE_KB, TBSP_USED_SIZE_KB, TBSP_FREE_SIZE_KB, TBSP_UTILIZATION_PERCENT from sysibmadm.tbsp_utilization with ur"

	db2 "select substr(TBSP_ID,1,5) as TBSP_ID, substr(TBSP_NAME,1,20) as TBSP_NAME,DBPARTITIONNUM , "TBSP_TYPE", TBSP_PAGE_SIZE / 1024 as TBSP_PAGE_SIZE_KB, TBSP_NUM_CONTAINERS, "TBSP_USED_PAGES", TBSP_USED_SIZE_KB / 1024 / 1024 as TBSP_USED_SIZE_GB from "SYSIBMADM"."TBSP_UTILIZATION" order by "TBSP_USED_PAGES" desc" 


'To change a tablespace form Regular to large'

	db2 "ALTER TABLESPACE <tbspacename> CONVERT TO LARGE"

'To Check/list what are the tablespaces using automatic storage'

	db2 "SELECT TBSP_NAME FROM SYSIBMADM.SNAPTBSP WHERE TBSP_USING_AUTO_STORAGE=1 AND TBSP_CONTENT_TYPE IN ('ANY','LARGE') ORDER BY TBSP_ID with ur"

'Identify all of the affected non temporary tablespaces that might have containers on the drop pending storage paths' #droppending #drop #pending

	db2 "SELECT DISTINCT A.TBSP_NAME FROM SYSIBMADM.SNAPTBSP A, SYSIBMADM.SNAPTBSP_PART B WHERE A.TBSP_ID = B.TBSP_ID AND A.TBSP_CONTENT_TYPE IN ('ANY','LARGE') AND 	B.TBSP_PATHS_DROPPED = 1"

-The following SQL statement generates a list of all the system temporary and user temporary automatic storage tablespaces in a database that have containers residing on a "Drop_Pending" path>

	db2 "SELECT DISTINCT A.TBSP_NAME FROM SYSIBMADM.SNAPTBSP A,SYSIBMADM.SNAPTBSP_PART B WHERE A.TBSP_ID = B.TBSP_ID AND A.TBSP_CONTENT_TYPE IN ('USRTEMP','SYSTEMP') AND B.TBSP_PATHS_DROPPED=1 "

' Quiesce exclusive on tablespace '

	db2 "quiesce tablespace for table schemaname.tablename reset"

Whenever you issue a Quiesce exclusive on tablespace , you canot reset from the instance level - it should be done at the user level only.. 

One Base rule, whenever you want yto login with anyother user other than instance user, you have to run the dot profile under that user. Or you can also set the dot profile under the user dot profile, so that when you login with that user , db2 env is automatically set for that user. If you not set the dot profile you will get db2 not found error..
#storagegroups

' Lowering the High Water Mark of a Tablespace ' 

	"db2dart testdb /dhwm /tsi 4 
	db2dart testdb /lhwm /tsi 6 /np 0 "
	
db2dart should never be run against a database that still has active connections. 

Refer <! http://www-01.ibm.com/support/docview.wss?uid=swg21006526>

END

*************************************
--< "TABLE or RANGE PARTITIONING" =>
*************************************

BEGIN

'DB2 partitioning features'

https://www.ibm.com/developerworks/data/library/techarticle/dm-0608mcinerney/

'Choosing partitioning keys in DB2 '

https://www.ibm.com/developerworks/data/library/techarticle/dm-1005partitioningkeys/
 
 'Choosing the right distribution keys in a DB2 DPF database'
 
http://db2commerce.com/2015/01/20/choosing-the-right-distribution-keys-in-a-db2-dpf-database/

'Distribution keys'

https://www.ibm.com/support/knowledgecenter/SSEPGG_10.5.0/com.ibm.db2.luw.admin.partition.doc/doc/c0004906.html

db2 "select tabschema, tabname, colname, partkeyseq from syscat.columns where tabname like 'TRANSACTION%' and partkeyseq !=0 order by partkeyseq with ur"

'Table partitioning '

https://www.ibm.com/support/knowledgecenter/en/SSEPGG_10.5.0/com.ibm.db2.luw.admin.partition.doc/doc/c0021557.html

'Partitioned tables'

https://www.ibm.com/support/knowledgecenter/SSEPGG_10.5.0/com.ibm.db2.luw.admin.partition.doc/doc/c0021560.html


'Unleash the power of table partitioning in your DB2 warehouse'

https://www.ibm.com/developerworks/data/library/techarticle/dm-1006tablepartitioning/index.html




https://db2talk.com/2015/04/28/why-you-should-specify-distribution-key-for-tables-in-a-single-database-partition-in-a-db2-dpf-database/

'Range-Partitions error and solution:' http://www-01.ibm.com/support/docview.wss?uid=swg21601085 

'DEtaching a partition:'
	
	ALTER TABLE NORKOMV6.TXN DETACH PARTITION PART71 INTO TABLE NORKOMV6.TXN_20141201_20150101_DETACH
'Rolling back previous operation:'

	alter table NORKOMV6.TXN attach partition  PART71 starting from (‘<20141201>’) ending (‘<20150101>’) exclusive from table NORKOMV6.TXN_20141201_20150101_DETACH;
	SET INTEGRITY FOR NORKOMV6.TXN immediate checked;
	
'Getting Generated Always Columns list from DB2'
	
		db2 "select identity, substr(tabname,1,30), substr(colname, 1, 30) from syscat.columns where tabschema='MYSCHEMA'"
			"Type of generated column"
				A = Column value is always generated
				D = Column value is generated by default
				Blank = Column is not generated

'find list of tables present in which partitions / nodegroup '
		db2 "select a.tabschema,a.tabname,a.tbspace,b.ngname, c.nodenum from syscat.tables a, syscat.tablespaces b,syscat.nodegroupdef c where a.tbspace = b.tbspace and b.ngname = c.ngname and tabschema not like 'SYS%'"
END
 
****************
--<' Schemas ='>
****************

BEGIN

'To list schema names in a database'

	db2 "select distinct tabschema from syscat.tables with ur" 
	db2 "select schemaname from syscat.schemata with ur"
	db2 "select substr(schemaname,1,30) from syscat.schemaauth with ur" | grep -vE "^--|SCHEMANAME|selected.|^1|^$" > outfile.lst 

'To list curent schema name'

	db2 values current schema

'To set the schema as current schema'

	db2 set current schema = <SCHEM1>

	END
	
****************************
--< TABLES..AND..INDEXES =>
****************************

BEGIN

'To list/describe indexes associated with a table'

	db2 "DESCRIBE INDEXES FOR TABLE <SCHEMA>.<TABLENAME> SHOW DETAIL"

'Find foreign key of a table '

	db2 "select substr(tabname,1,20) table_name,substr(constname,1,20) fk_name,substr(REFTABNAME,1,12) parent_table,substr(refkeyname,1,20) pk_orig_table,fk_colnames from syscat.references where tabname = '<TABLE_NAME>'"

'Find dependencies and Constraints from a list of tables'

	Note: We have to mention the list of tables in list_cvm.lst and then execute the below query:

	SELECT
     T.TABSCHEMA AS TABLE_SCHEMA
    ,T.TABNAME   AS TABLE_NAME
    ,CASE T.TYPE
        WHEN 'F' THEN 'Foreign Key'
        WHEN 'I' THEN 'Functional Dependency'
        WHEN 'K' THEN 'Check'
        WHEN 'P' THEN 'Primary Key'
        WHEN 'U' THEN 'Unique'
     END AS Type
    ,I.INDSCHEMA AS INDEX_SCHEMA
    ,I.INDNAME   AS INDEX_NAME
    ,U.COLNAME   AS COLUMN_NAME
    ,U.COLSEQ    AS COLUMN_ORDINAL
    ,CASE U.COLORDER
        WHEN 'A' THEN 'Ascending'
        WHEN 'D' THEN 'Descending'
        WHEN 'I' THEN 'Included (unordered)'
     END AS COLUMN_SORRING
FROM SYSCAT.TABCONST T
JOIN SYSCAT.CONSTDEP C
  ON T.CONSTNAME = C.CONSTNAME
JOIN SYSCAT.INDEXES I
  ON C.BSCHEMA = I.INDSCHEMA
 AND C.BNAME   = I.INDNAME
JOIN SYSCAT.INDEXCOLUSE U
  ON I.INDSCHEMA = U.INDSCHEMA
 AND I.INDNAME   = U.INDNAME
WHERE T.TABSCHEMA = '<SCHEMA_NAME>'
  AND T.TABNAME   = 'TABLE_NAME'
  AND C.BTYPE     = 'I' --Indexes Only
ORDER BY
     T.TABSCHEMA
    ,T.TABNAME
    ,I.INDSCHEMA
    ,I.INDNAME
    ,U.COLSEQ   ;
-------------------------------------------------------
'These two queries should produce scripts to drop and re-create foreign keys'
	SELECT 
	'ALTER TABLE schema.' || SUBSTR(TABNAME,1,50), 
	' DROP FOREIGN KEY ' || CONSTNAME || ';' 
	FROM 
	SYSCAT.REFERENCES 
	where 
	tabschema = 'schema';

	SELECT 
	'ALTER TABLE schema.' || SUBSTR(TABNAME,1,50), 
	'ADD CONSTRAINT ' || CONSTNAME, 
	'FOREIGN KEY (' || substr(FK_COLNAMES,1,50) || ')', 
	'REFERENCES schema.' || SUBSTR(REFTABNAME,1,17),  
	' ON DELETE ' || 
		case deleterule
		  when 'A' then 'NO ACTION' 
		  when 'C' then 'CASCADE' 
		  when 'N' then 'SET NULL' 
		  when 'R' then 'RESTRICT'
		end, 
	' ON UPDATE ' || 
		case updaterule
		  when 'A' then 'NO ACTION' 
		  when 'R' then 'RESTRICT'
		end 
	FROM 
		SYSCAT.REFERENCES 
	where 
		tabschema = 'schema' 
;
-------------------------------------------------------

'DDL Statements for foreign keys on Table table_name in the output'

	db2look -d <database_name> -t <table_name> -a -e -c -o foreign_key.out

'To Change the column_length of a column in a table'

	db2 "CALL SYSPROC.ALTOBJ ('APPLY_CONTINUE_ON_ERROR', 'CREATE TABLE "INST1"."EMPLOYEE" ("EMPNO" CHAR(6 OCTETS) NOT NULL ,"FIRSTNME" VARCHAR(12 OCTETS) NOT NULL ,"MIDINIT" CHAR(1 OCTETS) ,"LASTNAME" VARCHAR(15 OCTETS) NOT NULL ,"WORKDEPT" CHAR(3 OCTETS) ,"PHONENO" CHAR(4 OCTETS) ,"HIREDATE" DATE ,"JOB" CHAR(8 OCTETS) ,"EDLEVEL" SMALLINT NOT NULL ,"SEX" CHAR(1 OCTETS) ,"BIRTHDATE" DATE ,"SALARY" DECIMAL(9,2) ,"BONUS" DECIMAL(9,2) ,"COMM" DECIMAL(9,2) ) IN "USERSPACE1" ORGANIZE BY ROW', -1, ? )"

(OR)

	db2 "alter table <tablename> alter column <columnname> set data type decimal(9,2)"
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

'To see the size of a table / index' > #tablesize #indexsize

For Tables:

	db2 "select substr(a.tabname,1,30), (a.fpages*PAGESIZE/1024) as size_k,a.card from syscat.tables a, syscat.tablespaces b where a.TBSPACEID=b.TBSPACEID "

	db2 "select char(date(t.stats_time))||' '||char(time(t.stats_time)) as statstime ,substr(t.tabschema,1,4)||'.'||substr(t.tabname,1,24) as tabname , card as rows_per_table , decimal(float(t.npages)/ ( 1024 / (b.pagesize/1024)),9,2) as used_mb , decimal(float(t.fpages)/ ( 1024 / (b.pagesize/1024)),9,2) as allocated_mb from syscat.tables t , syscat.tablespaces b where t.tbspace=b.tbspace with ur" 


	db2 "select substr(t.tabschema,1,4)||'.'||substr(t.tabname,1,48) as tabname, card as rows_per_table, b.pagesize as pagesize, t.npages as npages, b.tbspaceid as tablespace, decimal(float(t.npages)/ ( 1024 / (b.pagesize/1024)),9,2) as used_mb, decimal(float(t.fpages)/ ( 1024 / (b.pagesize/1024)),9,2) as allocated_mb, ((decimal(float(t.npages)/ ( 1024 / (b.pagesize/1024)),9,2)) *1024*1024)/card as bytes_per_Row,  (decimal(float(t.npages)/ ( 1024 / (b.pagesize/1024)),9,2)) *1024*1024 as used_bytes from syscat.tables t, syscat.tablespaces b where card != -1 and card != 0 and b.tbspaceid = 4 order by tablespace, used_bytes DESC"
	
For Indexes:

	db2 "select rtrim(substr(i.tabschema,1,8))||'.'||rtrim(substr( i.tabname, 1,24)) as tabname , decimal(sum(i.nleaf)/( 1024 / (b.pagesize/1024)),12,2) as indx_used_pertable from syscat.indexes i, syscat.tables t , syscat.tablespaces b where i.tabschema is not null and i.tabname=t.tabname and i.tabschema=t.tabschema and t.tbspace=b.tbspace group by i.tabname,i.tabschema, b.pagesize with ur"

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

'To check the compression ratio'

	db2 "select TABNAME,TABSCHEMA,CARD,CLUSTERED,AVGCOMPRESSEDROWSIZE,AVGROWCOMPRESSIONRATIO,AVGROWSIZE,PCTROWSCOMPRESSED from sysstat.tables" 

'Table Compression'

	db2 "select substr ( a.tabschema,1,20 ) as tabschema, substr ( a.tabname,1,20 ) as tabname, a.card, rowcompmode, pctpagessaved, data_object_p_size, index_object_p_size, col_object_p_size,(data_object_p_size+index_object_p_size+col_object_p_size) as total_size_in_kb from syscat.tables a, sysibmadm.admintabinfo b where a.tabname = b.tabname and a.tabschema not like 'SYS%' and a.tabschema = b.tabschema with ur"

 #To check the actual compression savings for tables, you can use this

-> Be aware that it may run for a longer time

	db2 "SELECT substr(TABNAME,1,25) as TABLE_NAME, DICT_BUILDER, COMPRESS_DICT_SIZE, EXPAND_DICT_SIZE,PAGES_SAVED_PERCENT,BYTES_SAVED_PERCENT FROM SYSIBMADM.ADMINTABCOMPRESSINFO WHERE tabschema not like 'SYS%' and COMPRESS_DICT_SIZE > 0 order by 1 asc"

 'Check to determine the compression ratio estimate for a particular table or data set using ISNPECT tool'

- V9 -
	
	db2 INSPECT ROWCOMPESTIMATE TABLE NAME EMPLOYEE SCHEMA linges RESULTS KEEP inspect.out 
	
		(o/p will be saved in db2dump) to format the above file ==> db2inspf inspect.out inspect.log
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

'Set Integrity Concept'

	db2 -x "select 'SET INTEGRITY FOR '|| TABSCHEMA ||'.'||TABNAME || ' IMMEDIATE CHECKED;' from SYSCAT.TABLES where STATUS='C' and type='V'" > set_integrity.sql

	Typically, you need to manually perform integrity processing for a table in three situations: After loading data into a table;
	when altering a table by adding constraints on the table; and when altering a table to add a generated column.

Using the SET INTEGRITY statement to defer constraints checking:
db2 update employee set phoneno = '123' where empno = '000100'
db2 set integrity for employee off
db2 alter table employee add constraint phoneno_length check (length(rtrim(phoneno)) = 4)
db2 create table empl_except like employee
db2 set integrity for employee immediate checked for exception in employee use empl_except

SQL3602W Check data processing found constraint violations and moved them to
exception tables. SQLSTATE=01603

db2 select empno, lastname, workdept, phoneno from empl_except

EMPNO LASTNAME WORKDEPT PHONENO
------ --------------- -------- -------
000100 SPENSER E21 123


<EXAMPLE>

	db2 "alter table employee add column test generated always as (salary*50/100)" -> this will throw error 

	$ db2 "alter table employee add column test generated always as (salary*50/100)"
		DB21034E The command was processed as an SQL statement because it was not a 
		valid Command Line Processor command. During SQL processing it returned:
		SQL20054N The table "INST1.EMPLOYEE" is in an invalid state for the 
		operation. Reason code="22". SQLSTATE=55019 -->

	so issue the below command to know the state of that table 

		-> db2 load query table employee
		iff it is in normal state thenn issue the below command

		-> db2 set integrity for table employee off

		and thenn issue the alter command 

		-> db2 "alter table employee add column test generated always as (salary*50/100)"

		now the command will complete successfully....

		again check the status of the table
		db2 load query table employee
		
		db2 "select substr(tabschema,1,10) as tabschema,substr(tabname,1,20) tabname from sysibmadm.admintabinfo where load_status='PENDING'"

		it will be still in pending state, 

	To check what are the tables that in pending state 

		db2 "select tabname from syscat.tables where STATUS='C' and type='T'"

	To remove the pending state issue the below command

		db2 "set integrity for DEPARTMENT,EMPLOYEE,EMP_PHOTO,EMP_RESUME,PROJECT,PROJACT,EMPPROJACT immediate checked force generated" -> this command will remove the integrity pending from the table and its dependent tables..
		
'Generated column LOAD considerations'
	CREATE TABLE table1 (c1 INT,c2 INT,g1 INT GENERATED ALWAYS AS (c1 + c2),g2 INT GENERATED ALWAYS AS (2 * c1),c3 CHAR(1));
	
	"Loading data without generated columns"
		If you want to load TABLE1 with data from a file (load.del) that has been exported from a table that does not have any generated columns, see the following example:
		   1, 5, J
		   2, 6, K
		   3, 7, I
		One way to load this file ==>    DB2 LOAD FROM load.del of del REPLACE INTO table1 (c1, c2, c3);
		Another way "generatedmissing" ==> DB2 LOAD FROM load.del of del MODIFIED BY generatedmissing REPLACE INTO table1;
	
	"Loading data with generated columns"
		if you want to load the input file (listed below)- which has the generated column`s data but you want to ignore those use the following method 
   			1, 5, 10, 15, J
	        2, 6, 11, 16, K   
		    3, 7, 12, 17, I
		One way to load this file ==> DB2 LOAD FROM load.del of del method P(1, 2, 5) REPLACE INTO table1 (c1, c2, c3);
		Another way "generatedignore" ==> DB2 LOAD FROM load.del of del MODIFIED BY generatedignore REPLACE INTO table1;
	
	"Loading data with user-supplied values"
		if you want to load the user supplied generated column`s data use the following method
		
		"generatedoverride" ==> DB2 LOAD FROM load.del of del MODIFIED BY generatedoverride REPLACE INTO table1;
		BUT NOTE -> using of this generatedoverride modifier the table is placed in the Set Integrity Pending state after the load operation
		To take the table out of Set Integrity Pending state 'without verifying the user-supplied values'
					"SET INTEGRITY FOR table-name GENERATED COLUMN IMMEDIATE UNCHECKED;"
 		To take the table out of the Set Integrity Pending state and 'force verification of the user-supplied values', issue the following command:
					"SET INTEGRITY FOR table-name IMMEDIATE CHECKED"
					
					
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

'Select to identify tables that have LOB columns that are stored together with the data' #LOBColumn 

	db2 "select substr(t.OWNER,1,12) schema, substr(t.TABNAME,1,30) tab, substr(c.COLNAME,1,30) col, t.TBSPACEID, t.TABLEID from SYSCAT.COLUMNS c, SYSCAT.TABLES t where c.TYPENAME in ('BLOB','CLOB','LONG VARCHAR') and c.TABNAME = t.TABNAME and t.TBSPACEID <> 0 and t.LONG_TBSPACE is null" 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

'To determine if an index needs rebuilding and how to monitor index rebuilds to know if they have completed' #indexrebuild #rebuild #indexmon #monitor

1.Using the inspect database tool. For example:

Issue the command:
	db2 "inspect check database for error state all results keep inspect.out"

Thenn cd to the DIAGPATH.
For example on UNIX®, this would be: cd $INSTHOME/sqllib/db2dump

Issue the command:
db2inspf inspect.out inspect.fmt

If you view the corresponding inspect.fmt file, a message similar to the following will appear:
Index phase start. Object: 3 Tablespace: 2
Warning: Object is known to be in error state x400.
Warning: Index object is in invalid state, requires index be re-built.


2.Using the database analysis and reporting tool (db2dart). For example:

If you have a specific table to query, issue the following command:
	db2 "select tableid,tbspaceid,tabname,tabschema from syscat.tables where tabname = '<name of your table>'"

Thenn run the db2dart tool: "
	
	db2dart <dbname> /T /TSI <tbspaceid from above> /OI <tableid from above>
"
View the <dbname>.RPT (found in your DIAGPATH). Look for a message similar to the following:
Index phase start. Object: 3 Tablespace: 2
Warning: Object is known to be in error state x400.
Warning: Index object is in invalid state, requires index be re-built.

3. Query sysproc.admin_get_index_info admin view. 

	db2 "select substr(indname,1,30) INDNAME,iid, index_requires_rebuild,INDEX_OBJECT_P_SIZE FROM TABLE(sysproc.admin_get_index_info('T','<Schema_Name>','TABLE_NAME'))"

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

END

***************************************
--< BACKUPS..AND..RESTORE..COMMANDS =>
***************************************

BEGIN

'To find out time of backup start and end'

	db2 "SELECT start_time, end_time, operationtype FROM SYSIBMADM.DB_HISTORY where operation='B' and SQLCODE is null and SQLERRMC is null order by START_TIME desc fetch first 30 rows only" | more
	
	db2 "select distinct (case operationtype when 'D' then 'Delta offline' when 'E' then 'Delta online' when 'F' then 'FULL Offline' when 'I' then 'Incremental offline' when 'N' then 'FULL Online' when 'O' then 'Incremental online' end) as backupType , START_TIME, end_time, dbpartitionnum,timestampdiff (4, char(timestamp(end_time)- timestamp(start_time))) as run_minute,SQLCODE,substr(SQLERRMC,1,20) sqlerrmc from sysibmadm.db_history where OPERATION = 'B' and start_time = ( select Max(start_time) from sysibmadm.db_history where OPERATION = 'B') order by START_TIME,DBPARTITIONNUM  with ur"

	db2 list history backup all for db <dbname>

'To list the metadata of the backup'
	 
	 db2ckbkp -H <full_backup_image_name>

'Check the restore history'

	db2 "select START_TIME, END_TIME,OPERATION, operationtype from sysibmadm.db_history where OPERATION='R' with ur"

Types Description: 
F Full Offline
M Merge
B Backup
N Online
I Incremental offline
O Incremental online
D Delta offline
E Delta online
R Rebuild


' BAckup Long Running ' #BAckupslow #slowbackup #logrunningbackup

http://thinkingdb2.blogspot.in/2015/03/understanding-and-tuning-db2luw-backup.html

'Analysing DB2_BAR_STATS' 

enabled by default form v10.1 FP2: #dbcfg

http://www.idug.org/p/bl/et/blogid=278&blogaid=518?cm_mc_uid=16872915415414048314596&cm_mc_sid_50200000=1480731048


'Check for the below entry to find out the size of the backup image in diag.log' #backupsize #size 

	2016-12-02-21.35.19.480431-300 E2022969A538 LEVEL: Info
	PID : 8520040 TID : 17312 PROC : db2sysc 14
	INSTANCE: dssprod NODE : 014 DB : DSSPRDB
	APPHDL : 0-14465 APPID: *N0.dssprod.161202230747
	AUTHID : DBABATCH HOSTNAME: NA940172-SAL
	EDUID : 17312 EDUNAME: db2agntp (DSSPRDB) 14
	FUNCTION: DB2 UDB, database utilities, sqluxLogDataStats, probe:422
	MESSAGE : Actual size of backup in bytes:
	DATA #1 : unsigned integer, 8 bytes
	43201769472

	
END

***********************************************************
-- RUNSTATS_REORG_REORGANINZATION_STATISTICS_COLLECTION =>
***********************************************************

BEGIN

'To list out What Tables need Reorg'

1.	db2 reorgchk current statistics on table <schema>.<tablename>

2.	----->>-REORGCHK_TB_STATS--(--scope--,--criteria--)----------------->

		Scope - T or S

		If scope has a value of 'T', specifies a fully qualified table name, or accepts one of the following values: ALL, USER, or SYSTEM. If scope has a value of 'S', specifies a schema name.

<Example>

	db2 "CALL REORGCHK_TB_STATS('T', 'ALL')" | grep "*" | awk '{print $1"."$2" " $8}' 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

SCRIPT TO CHECK REORGCHK - TABLE NEED REORG #reorgcheck #reorgchk 
--=============================================
--Analysis to find candidates for a Table Reorg
--=============================================
-- PROBLEM: Tables with excessive Space to reclaim
-- OFFLINE Table Reorgs will reclaim all possible space
-- ONLINE Table Reorgs can reclaim some space but usually not all
-- Should only consider OFFLINE Reorg if > 5GB and > 10% of table space can be reclaimed.
-- all tables that are range partitioned
select char(trim(st.tabschema)||'.'||rtrim(st.tabname),45) TABLE
, 'RangePart' as PARTITIONED
, st.npages
, st.fpages
, (st.fpages-st.npages)*mgtb.TBSP_PAGE_SIZE/1024/1024/1024 SPACE_TO_RECLAIM_GB
, (100*(st.fpages-st.npages)/st.fpages) PCT_Space_Saved
from TABLE(MON_GET_TABLE('','',-2)) AS mgt
INNER JOIN syscat.tables st
on st.tabschema = mgt.tabschema
and st.tabname = mgt.tabname
and mgt.DATA_PARTITION_ID is not null
and mgt.DATA_PARTITION_ID =
(Select min(mgt1.DATA_PARTITION_ID)
from TABLE(MON_GET_TABLE(mgt.tabschema,mgt.tabname,-2)) as mgt1
-- where mgt.tabschema = mgt1.tabschema
-- and mgt.tabname = mgt1.tabname
)
INNER JOIN TABLE(MON_GET_TABLESPACE('',-2)) AS mgtb
on mgt.tbsp_id = mgtb.tbsp_id
-- from syscat.tables
where ((st.fpages-st.npages)*mgtb.TBSP_PAGE_SIZE/1024/1024/1024) > 5 --can reclaim more than 5GB
and (100*(st.fpages-st.npages)/st.fpages) > 10 --will reclaim more than 10% freespace
UNION ALL
-- all tables that are not range partitioned
select char(trim(st.tabschema)||'.'||rtrim(st.tabname),45) TABLE
, 'NotParted' as PARTITIONED
, st.npages
, st.fpages
, (st.fpages-st.npages)*mgtb.TBSP_PAGE_SIZE/1024/1024/1024 SPACE_TO_RECLAIM_GB
, (100*(st.fpages-st.npages)/st.fpages) PCT_Space_Saved
from TABLE(MON_GET_TABLE('','',-2)) AS mgt
INNER JOIN syscat.tables st
on st.tabschema = mgt.tabschema
and st.tabname = mgt.tabname
and mgt.DATA_PARTITION_ID is null
INNER JOIN TABLE(MON_GET_TABLESPACE('',-2)) AS mgtb
on mgt.tbsp_id = mgtb.tbsp_id
-- from syscat.tables
where ((st.fpages-st.npages)*mgtb.TBSP_PAGE_SIZE/1024/1024/1024) > 5 --can reclaim more than 5GB
and (100*(st.fpages-st.npages)/st.fpages) > 10 --will reclaim more than 10% freespace
order by 5 desc
;
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

<' Reorg and runstats command '>

	db2 "reorg table <SCHEMA>.<TABLENAME> allow read access"
	db2 "runstats on table <SCHEMA>.<TABLENAME> with distribution on all columns and indexes all allow read access" 

<' REORG MONITOR '> #reorgmonitor

To monitor an OFFLINE REORG you can use one of the following methods: #reorg #starttime #endtime #startend

	1. db2 get snapshot for tables on sample
	2. db2pd -db sample -reorg (Starting DB2 V9.5 FP5 and DB2 V9.7 FP1)
	3. db2 list history reorg all for sample
	4. db2 " SELECT SUBSTR(TABNAME, 1, 20) AS TAB_NAME, SUBSTR(TABSCHEMA, 1, 15) AS TAB_SCHEMA, SUBSTR(REORG_TYPE, 1, 35) AS REORG_TYPE,REORG_PHASE,REORG_STATUS,REORG_COMPLETION,REORG_START,REORG_END FROM SYSIBMADM.SNAPTAB_REORG"

To Monitor an INPLACE REORG, you can use:

	1. SNAPTAB_REORG administrative view or the SNAP_GET_TAB_REORG table function and check the REORG_TYPE
	2. db2 "SELECT SUBSTR(TABNAME, 1, 15) AS TAB_NAME, SUBSTR(TABSCHEMA, 1, 15) AS TAB_SCHEMA,INPLACE_REORG_STATUS FROM TABLE (SYSPROC.ADMIN_GET_TAB_INFO('<SCHEMA>','<TABLE>'))"
	3. List History Reorg -- the type is 'N' ,this indicates an inplace reorg

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
<' Reorg Phases: '>

1. there are four phases in a classic or offline table reorganization operation:

SORT -  During this phase, if an index was specified on the REORG TABLE command, or a clustering index was defined on the table, the rows of the table are first sorted        according to that index.
		If the INDEXSCAN option is specified, an index scan is used to sort the table; otherwise, a table scan sort is used. This phase applies only to a clustering table REORG operation. 
		Space reclaiming REORG operations beegin at the build phase.

BUILD - During this phase, a reorganized copy of the entire table is built, either in its table space or in a temporary table space that was specified on the REORG 	   TABLE command.

REPLACE - During this phase, the original table object is replaced by a copy from the temporary table space, or a pointer is created to the newly built object within the 
          table space of the table that is being reorganized.

RECREATE ALL INDEXES - During this phase, all indexes that were defined on the table are re-created.


2. There are four main phases in an online table REORG operation:

SELECT N PAGES -    During this phase, the database manager selects a range of n pages, where n is the size of an extent with a minimum of 32 sequential pages for REORG                    processing.

VACATE THE TABLE -  The REORG utility moves all rows within this range to free pages in the table. Each row that is moved leaves behind a REORG table pointer (RP)
					record that contains the record ID (RID) of the rows new location. The row is placed on a free page in the table as a REORG table overflow (RO) 
					record that contains the data. After the utility finishes moving a set of rows, it waits until all applications that are accessing data in the table are finished. 
					These "old scanners" use old RIDs when table data is accessed. Any table access that starts during this waiting period (a "new scanner") uses new RIDs to access the data. 
					After all of the old scanners are complete, the REORG utility cleans up the moved rows, deleting RP records and converting RO records into regular records.

FILL THE RANGE -    After all rows in a specific range are vacated, they are written back in a reorganized format, they are sorted according to any indexes that were                    used, and obeying any PCTFREE restrictions that were defined. When all of the pages in the range are rewritten, the next n sequential pages in the                    table are selected, and the process is repeated.

TRUNCATE THE TABLE - By default, when all pages in the table are reorganized, the table is truncated to reclaim space. If the NOTRUNCATE option is specified, the                     reorganized table is not truncated.
 
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

' RUNSTATS MONITOR '  #runstatsmonitor

		db2 "SELECT UTILITY_PRIORITY, SUBSTR(UTILITY_DESCRIPTION, 1, 72) AS UTILITY_DESCRIPTION, SUBSTR(UTILITY_DBNAME, 1, 17) AS UTILITY_DBNAME, UTILITY_STATE, UTILITY_INVOKER_TYPE, DBPARTITIONNUM FROM SYSIBMADM.SNAPUTIL WHERE UTILITY_TYPE='RUNSTATS' ORDER BY DBPARTITIONNUM" 

		db2pd -d <dbname> -runstats

' Using the statistics logs to find tables with long RUNSTATS time ' > #longrunstats

		db2 "select timestamp(varchar(substr(first_eventqualifier,1,26),26)) as eventtime, substr(objname_qualifier,1,20) as objschema, substr(objname,1,15) as objname, substr(eventtype,1,8) as eventtype,substr(second_eventqualifier,1,10) eventby, substr(eventstate,1,10) as eventstate from table(sysproc.PD_GET_DIAG_HIST('optstats','EX','NONE',null,cast(null as timestamp))) as sl order by eventtime desc" 

<!- Output look like the below

EVENTTIME					 OBJSCHEMA			 OBJNAME 			EVENTTYPE EVENTBY	 EVENTSTATE
2015-08-17-01.14.39.434321 		PSADM 		PS_PAYROLL_DATA 		COLLECT 	User 		success
2015-08-17-01.14.36.318155 		PSADM 		PS_PAYROLL_DATA 		COLLECT 	User 		start
2015-08-17-01.14.36.269407 		PSADM 		PS_ORGEMP_SPLT_ 		COLLECT 	User 		success
2015-08-17-01.14.36.062466 		PSADM 		PS_ORGEMP_SPLT_ 		COLLECT 	User 		start
2015-08-17-01.14.36.010596 		PSADM 		PS_OHS501UK_TMP 		COLLECT 	User 		success 

use where clause on objname to identify time elapse on a particular table.-->

<'Throttling in RUNSTATS'>

	db2 "UPDATE DBM CFG USING UTIL_IMPACT_LIM 10"
	db2 "RUNSTATS ON TABLE DB2USER.EMPLOYEE WITH DISTRIBUTION DEFAULT NUM_FREQVALUES 50 UTIL_IMPACT_PRIORITY 60"

The above command specifies the RUNSTATS command will be throttled with a priority of 60 (relative to other throttled utilities).

Automatic statistics collection uses a fixed impact rate of 7 percent no matter how much UTIL_IMPACT_LIM is set. This way ensures automatic statistics collection does not have a significant impact on your workload even if it runs during production hours.
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

END

******************************************
--<'AUTHORIZATION..PRIVILEGES..ACCESS' =>
******************************************

BEGIN

'All columns in <syscat.dbauth>'

	db2 "select distinct substr(grantor,1,10) as grantor,grantortype, substr(grantee,1,10) as grantee, granteetype,BINDADDAUTH ,CONNECTAUTH,CREATETABAUTH,DBADMAUTH,EXTERNALROUTINEAUTH,IMPLSCHEMAAUTH,LOADAUTH,NOFENCEAUTH,QUIESCECONNECTAUTH,LIBRARYADMAUTH,SECURITYADMAUTH,SQLADMAUTH,WLMADMAUTH,EXPLAINAUTH,DATAACCESSAUTH,ACCESSCTRLAUTH from syscat.dbauth with ur"

'All columns in <syscat.tabauth>'

	db2 "SELECT substr(grantor,1,8) AS grantor,SUBSTR(grantee,1,8) AS grantee, granteetype AS gtype,SUBSTR (tabschema,1,8) AS schema,SUBSTR (tabname,1,8) AS tabname,controlauth AS ctl,alterauth AS alt,deleteauth AS del,indexauth AS idx,insertauth AS ins,selectauth AS sel,refauth AS ref,updateauth AS upd FROM syscat.tabauth"

'All columns in <SYSPROC.AUTH_LIST_AUTHORITIES_FOR_AUTHID>' #find the privileges for a particular person and his/her group - need to mention ID in the below command

	db2 "SELECT substr(AUTHORITY,1,25) as AUTH, D_USER, D_GROUP, D_PUBLIC, ROLE_USER, ROLE_GROUP, ROLE_PUBLIC FROM TABLE (SYSPROC.AUTH_LIST_AUTHORITIES_FOR_AUTHID ('VN2782', 'U') ) AS T ORDER BY AUTHORITY"

  ->(change object type and privilege in where clause to excel more)

	db2 "SELECT SUBSTR(AUTHID,1,16) as AUTHID, AUTHIDTYPE, PRIVILEGE, SUBSTR(OBJECTNAME,1,20) as OBJECTNAME, SUBSTR(OBJECTSCHEMA,1,10) as OBJECTSCHEMA, substr(OBJECTTYPE,1,10) as objecttype FROM SYSIBMADM.PRIVILEGES where objecttype='SEQUENCE' and privilege='USAGE' order by authid"


'To find roles under user ids - < sysproc.auth_list_roles_for_authid > '

	db2 "select substr(grantor,1,10) as grantor, grantortype, substr(grantee,1,10) as grantee, granteetype, substr(rolename,1,10) as rolename from table (sysproc.auth_list_roles_for_authid('USERID','U')) as T where rolename not like 'SYS%'"

' Find out all valid user packages that have dependency on sequences '

	db2 "select char(a.pkgschema, 10)pkgschema, char(a.pkgname, 20)pkgname, char(boundby,10)boundby, valid, char(bschema,10)bschema, char(bname,10)bname from syscat.packages a, syscat.packagedep b where a.pkgschema=b.pkgschema and a.pkgname=b.pkgname and b.btype='Q' and bschema not like 'SYS%' order by boundby"

'To grant to many tables at a time'

	db2 -tnx "select distinct 'GRANT ALL ON TABLE '||'\"'||rtrim(tabschema)||'\".\"'||rtrim(tabname)||'\" TO USER <USERNAME>;' from syscat.tables " >> grants.sql

Below query will grant the select access to a particular user on all the tables under syscat.tabscles:(Need to fill up the user id that you are working with:)

	SELECT DISTINCT substr('GRANT SELECT ON TABLE ' || rtrim(T.TABSCHEMA) || '.' || rtrim(T.TABNAME) || ' TO user <USERID>;', 1, 95)
	FROM SYSCAT.TABLES T
	, SYSCAT.TABAUTH A
	WHERE A.TABNAME NOT IN (
	SELECT TABNAME
	FROM SYSCAT.TABAUTH A
	WHERE GRANTEE = '<USERID>'
	AND SELECTAUTH = 'Y'
	)
	AND A.TABNAME = T.TABNAME
	AND A.TABSCHEMA = T.TABSCHEMA
	AND T.TYPE in ('T','V')
	AND T.TABSCHEMA not like 'SYS%'
	;

'Granting based on the create time'

	db2 -tnx "select distinct 'GRANT SELECT ON TABLE '||'\"'||rtrim(tabschema)||'\".\"'||rtrim(tabname)||'\" TO GROUP <GROUPNAME>;' from syscat.tables where create_time > <'2015-07-17-15.15.00.000000'> and tabname not like 'SYN%'" >> scrbprdb_new_table_grants_CDLSVIDP.sql

'Other grants'

	GRANT USAGE ON WORKLOAD SYSDEFAULTUSERWORKLOAD TO GROUP <username> ;

	GRANT BIND, EXECUTE ON PACKAGE NULLID.SYSSH100 TO GROUP <username> ;





'if you dont want any user to be able to know what objects other users have access to, you should consider restricting access to the following catalog and administrative views'

	SYSCAT.COLAUTH
	SYSCAT.DBAUTH
	SYSCAT.INDEXAUTH
	SYSCAT.PACKAGEAUTH
	SYSCAT.PASSTHRUAUTH
	SYSCAT.ROUTINEAUTH
	SYSCAT.SCHEMAAUTH
	SYSCAT.SECURITYLABELACCESS
	SYSCAT.SECURITYPOLICYEXEMPTIONS
	SYSCAT.SEQUENCEAUTH
	SYSCAT.SURROGATEAUTHIDS
	SYSCAT.TABAUTH
	SYSCAT.TBSPACEAUTH
	SYSCAT.XSROBJECTAUTH
	SYSIBMADM.AUTHORIZATIONIDS
	SYSIBMADM.OBJECTOWNERS
	SYSIBMADM.PRIVILEGES

This would prevent information on user privileges from becoming available to everyone with access to the database.

**************************************************************************************************************************

END

*************************************
--<" Data Movements and Utilities ">
*************************************

BEGIN

#data movement #datautilities #utility #db2move #db2import #export #load  

https://www.ibm.com/developerworks/data/tutorials/db2-cert6115/ -> overview of all utilities

< #admin_copy #admin_move #admin_drop #copy_schema #drop_schema #stored procedures #call_procedures >

<'Admin_table_move'> 

	https://www.ibm.com/support/knowledgecenter/en/SSEPGG_10.5.0/com.ibm.db2.luw.sql.rtn.doc/doc/r0055069.html
	
	http://db2commerce.com/2016/03/08/using-db2s-admin_move_table-to-move-tables-from-one-tablespace-to-another/
	https://www.ibm.com/developerworks/data/library/techarticle/dm-1306adminmovetable/#9.5
	
<'To copy schemas'>

	>>-ADMIN_COPY_SCHEMA--(--sourceschema--,--targetschema--,------->

	>--copymode--,--objectowner--,--sourcetbsp--,--targettbsp--,---->

	>--errortabschema--,--errortab--)------------------------------>

<Example>
	db2 "CALL SYSPROC.ADMIN_COPY_SCHEMA('INST1', 'INST3','COPYNO', NULL, NULL, NULL, 'ERRORSCHEMA', 'ERRORNAME')"


<' To drop schema '>

	>>-ADMIN_DROP_SCHEMA--(--schema--,--dropmode--,----------------->

	>--errortabschema--,--errortab--)------------------------------>

<Example>
	db2 "CALL SYSPROC.ADMIN_DROP_SCHEMA('INST3', NULL, 'ERRORSCHEMA', 'ERRORTABLE')"

<' To get the dependencies on a table '>

	>>-DBMS_UTILITY.GET_DEPENDENCY--(--type--,--schema--,--name--)->

<Example>
	db2 "CALL DBMS_UTILITY.GET_DEPENDENCY('TABLE', 'NEWSCHEMA', 'NEWTABLE')"

**************************************************************************************************************************

END

******************************
--<'MONITORING..ACTIVITIES'=>
******************************

BEGIN

	db2 UPDATE MONITOR SWITCHES USING BUFFERPOOL ON LOCK ON SORT ON STATEMENT ON TABLE ON TIMESTAMP ON UOW ON Global


<'EVENT MONITORING'> #db2evmon #deadlock #locktimeout #locks 

	http://db2commerce.com/2012/01/23/analyzing-deadlocks-the-new-way/

	https://xcoolwinds.wordpress.com/2013/08/30/using-db2evmonfmt-tool-for-reading-event-monitor-data/

	http://www.ibm.com/developerworks/data/library/techarticle/dm-1004lockeventmonitor/

	http://db2virtual.com/db2blog/blog/2016/01/12/db2-event-monitor-for-locktimeout-and-deadlock/


<' New lock timeout reporting capabilities in DB2 9.5 '> 

To activate lock timeout reporting, just set the DB2 registry variable DB2_CAPTURE_LOCKTIMEOUT to ON, and restart your DB2 instance
DB2 automatically creates a report file for each lock timeout occurrence. The report file is written to the directory where the DIAGPATH database manager configuration (DBM CFG) parameter.

	db2set DB2_CAPTURE_LOCKTIMEOUT=ON
	db2stop
	db2start

refer -> https://db2forum.wordpress.com/2011/10/17/new-options-for-analyzing-lock-timeouts-in-db2-9-5/

<' lock event monitor in DB2 9.7 to solve concurrency issues '>

To create event monitors for deadlocks (defaultly enabled and available when creating a database and starts automatically when the database starts)

reference -> https://db2forum.wordpress.com/2011/10/17/lock-event-monitor-in-db2-9-7-to-solve-concurrency-issues/

Ex-1
	db2 CREATE EVENT MONITOR DB2DETAILDEADLOCK FOR DEADLOCKS WITH DETAILS WRITE TO FILE 'DB2DETAILDEADLOCK' MAXFILES 20 MAXFILESIZE 512 BUFFERSIZE 17 BLOCKED APPEND AUTOSTART

Ex-2
create the lock event monitor. Select a name of the lock event monitor itself and of its corresponding unformatted event table. 
In the example, the lock event monitor is called EVMON_LOCKING. The unformatted event table is called TAB_LOCKING in schema EMDATA. 
Specifying the IN-clause, the table is placed in its own tablespace TBSPACE_LOCKING.

	db2 "CREATE TABLESPACE TBSPACE_LOCKING"
	db2 "CREATE EVENT MONITOR EVMON_LOCKING FOR LOCKING WRITE TO UNFORMATTED EVENT TABLE (TABLE EMDATA.TAB_LOCKING IN TBSPACE_LOCKING)"

<'DBLevel Lock Monitoring'>

MON_DEADLOCK, MON_TIMEOUT, and MON_LOCKWAIT - When activating any of these parameters, the lock event monitor observes all database sessions independently of application name, authorization ID, and other parameters for the occurrence of the corresponding lock event: deadlock, lock-timeout, or lock-wait.

	db2 "UPDATE DB CFG USING MON_DEADLOCK HISTORY IMMEDIATE"

Example to create a deadlock: (sample database)

	session1 : db2 +c "UPDATE DEPARTMENT SET LOCATION = 'New York' WHERE DEPTNO = 'B01'"
	session2: db2 +c "UPDATE DEPARTMENT SET DEPTNAME = 'OPERATIONS 1' WHERE DEPTNO = 'E11'"
	db2 +c "UPDATE DEPARTMENT SET DEPTNAME = 'PLANNING 1' WHERE DEPTNO = 'B01'"
	Session1: db2 +c "UPDATE DEPARTMENT SET LOCATION = 'Los Angeles' WHERE DEPTNO = 'E11'"

The database manager automatically rolls back one of the transactions, either the one in the first session or the one in the second session

Format the event mon file to see the results

< 'Workload-level Lock Monitoring '>

	For starting - db2 "ALTER WORKLOAD SYSDEFAULTUSERWORKLOAD COLLECT LOCK TIMEOUT DATA WITH HISTORY" -> For SYSDEFAULTUSERWORKLOAD, the lock event monitor captures all lock-timeout events.
	
	For stopping - db2 "ALTER WORKLOAD SYSDEFAULTUSERWORKLOAD COLLECT LOCK TIMEOUT DATA NONE"

Format the event mon file to see the results

'To check the Event Monitor status'

	db2 "select evmonname, event_mon_state(evmonname) as enabled,TARGET from syscat.eventmonitors with ur" 

' To enable or disable '
	
	db2 "SET EVENT MONITOR <evntmonname> STATE 0 | 1"

To view the output:
	
	" db2evmon -path <event-monitor-target>(0000*.evt) (-file option available) "


find /opt/db2path/tlogprdb -name "db2detaildeadlock"

********************************************************************************************************************

<' Listing the applications in lock-wait and identifing the application and SQL causing the lock '> #lockmon

	db2 list applications show detail | grep -i lock

	db2 "select agent_id as WAITING_FOR_LOCK, agent_id_holding_lk as HOLDING_LOCK,table_name, LOCK_WAIT_START_TIME as LOCK_WAIT_START_TIME from table(snapshot_lockwait('<dbname>', -1)) as slw order by 4 ASC" -> <'Second column will list the agentid holding the lock'>

	This will show you the SQL executed by each agentid, with the agent id issue the below command
		
		db2 "get snapshot for application agentid <agentid> "
	
<' Lock wait time for applications'> #lockwait

	db2 "select substr(ai.appl_name,1,20) as appl_name ,substr(ai.primary_auth_id,1,10) as auth_id , ap.agent_id as app_handle,ap.lock_waits as lock_waits, ap.lock_wait_time/1000 as Total_Wait_S,(ap.lock_wait_time / ap.lock_waits ) as Avg_Wait_ms from sysibmadm.snapappl_info ai, sysibmadm.snapappl ap where ai.agent_id = ap.agent_id and ap.lock_waits > 0"

<' Monitoring performance with SQL -Lock escalations, deadlocks and timeouts '> #lockesc 

	db2 "select substr(ai.appl_name,1,10) as Application, substr(ai.primary_auth_id,1,10) as AuthID, int(ap.locks_held) as N_Locks,int(ap.lock_escals) as Escalations, int(ap.lock_timeouts) as Lock_Timeouts,int(ap.deadlocks) as Deadlocks, int(ap.int_deadlock_rollbacks) as Dlock_Victim, substr(inbound_comm_address,1,15) as IP_Address from sysibmadm.snapappl ap, sysibmadm.snapappl_info ai where ap.agent_id = ai.agent_id"

<' To list lock chain --> which is holding which '> #lockchain

	db2 "select substr(ai_h.appl_name,1,10) as Hold_App, substr(ai_h.primary_auth_id,1,10) as Holder, substr(ai_w.appl_name,1,10) as Wait_App, substr(ai_w.primary_auth_id,1,10) as Waiter, lw.lock_mode as Hold_Mode,lw.lock_object_type as Obj_Type,substr(lw.tabname,1,10) as TabName, substr(lw.tabschema,1,10) as Schema, timestampdiff(2,char(lw.snapshot_timestamp - lw.lock_wait_start_time)) as waiting_sec from sysibmadm.snapappl_info ai_h, sysibmadm.snapappl_info ai_w, sysibmadm.snaplockwait lw where lw.agent_id = ai_w.agent_id and lw.agent_id_holding_lk = ai_h.agent_id"

<' Applications connect time '>

	db2 "select APPLICATION_HANDLE,CONNECTION_START_TIME , substr(client_hostname,1,15) as hostname from table(mon_get_connection(null,-2)) "
	
********************************************************************************************************************

< 'Monitoring and identifying transaction log space issue' > #monlog #logmon

	db2 "SELECT * FROM SYSIBMADM.LOG_UTILIZATION"

	db2 " select LOG_UTILIZATION_PERCENT as LOG_UTILIZATION_PERCENT, int(TOTAL_LOG_USED_KB/1024) as TOTAL_LOG_USED_MB,int(TOTAL_LOG_AVAILABLE_KB/1024) as TOTAL_LOG_AVAILABLE_MB, int(TOTAL_LOG_USED_TOP_KB/1024) as TOTAL_LOG_USED_TOP,MEMBER from sysibmadm.MON_TRANSACTION_LOG_UTILIZATION"

	O/P:
	
		LOG_UTILIZATION_PERCENT TOTAL_LOG_USED_MB TOTAL_LOG_AVAILABLE_MB TOTAL_LOG_USED_TOP MEMBER
		----------------------- ----------------- ---------------------- ------------------ ------
		7.40  7165 89637 7165 0


	db2 "select int(total_log_used/1024/1024) as Log_Used_Meg, int(total_log_available/1024/1024) as Log_Space_Free_Meg, int((float(total_log_used) /float(total_log_used+total_log_available))*100) as Percent_Used,int(tot_log_used_top/1024/1024) as Max_Log_Used_Meg, int(sec_log_used_top/1024/1024) as Max_Secundary_Used_Meg, int(sec_logs_allocated) as Secondaries from sysibmadm.snapdb" 

<' To list transactions that are holding too much log space ' > #logutil #logspace #logmon

Below query shows the 'log usage as well as the application holding the oldest transaction logs' >

	db2 "SELECT substr(DB_NAME,1,10) AS DSSTSDB, CASE (TOTAL_LOG_AVAILABLE) WHEN -1 THEN DEC(-1,5,2) ELSE DEC(100 * (FLOAT(TOTAL_LOG_USED)/FLOAT(TOTAL_LOG_USED + TOTAL_LOG_AVAILABLE)), 5,2) END AS Log_used_perc, TOTAL_LOG_USED/1024/1024 AS Total_log_used_MB, CASE (TOTAL_LOG_AVAILABLE) WHEN -1 THEN -1 ELSE TOTAL_LOG_AVAILABLE/1024/1024 END AS Total_log_available_MB, TOT_LOG_USED_TOP/1024/1024 AS Total_log_used_TOP_MB, APPL_ID_OLDEST_XACT AS ID_oldest_transaction, DBPARTITIONNUM,LOG_HELD_BY_DIRTY_PAGES FROM SYSIBMADM.SNAPDB"

	db2 "SELECT (AI.APPL_STATUS) as Status, SUBSTR(AI.PRIMARY_AUTH_ID,1,10) AS Authid,AI.AGENT_ID, SUBSTR(AI.APPL_NAME,1,15) AS Appl_Name, int(AP.UOW_LOG_SPACE_USED/1024/1024) AS Log_Used_MB, INT(AP.APPL_IDLE_TIME/60) AS Idle_for_min, AP.APPL_CON_TIME AS Connected_Since FROM SYSIBMADM.SNAPDB DB, SYSIBMADM.SNAPAPPL AP,SYSIBMADM.SNAPAPPL_INFO AI WHERE AI.AGENT_ID = DB.APPL_ID_OLDEST_XACT AND AI.AGENT_ID = AP.AGENT_ID" 

		above query Displays information about the application that currently has the oldest uncommitted unit of work.This is useful if to know about transactions that are holding too much log space.

	db2 "SELECT TOTAL_LOG_AVAILABLE AS LOG_AVAILABLE,TOTAL_LOG_USED as LOG_USED, APPL_ID_OLDEST_XACT as OLDEST_APPL_ID from SYSIBMADM.SNAPDB"

		(APPL_ID_OLDEST_XACT will give you the agentid holding on to the transacation log)


<' to list how many free logs are availble '>

	db2 "select int((float(total_log_used)/float(total_log_used+total_log_available))*100) from sysibmadm.snapdb" 

<' LOG HWM '>

	db2 "SELECT int(sec_log_used_top/1024/1024) as Sec_LOG_HWM, int(tot_log_used_top/1024/1024) as TOT_LOG_HWM, int(total_log_used/1024/1024) as TOT_LOG_USED, int(total_log_available/1024/1024) as AVAILABLE_LOGS FROM TABLE(SNAP_GET_DB('SAMPLE',-1 )) as SNAPSHOT_DATABASE" <- - - check this - seems not working


	db2 get snapshot for application agentid <agentid.from.above.sql> | grep -i -e "Application handle" -e "UOW log space used"

	db2 update monitor switches uow on

	db2pd -d <dbname> -transactions  -> look for Space reserverd and Log space attribute values

********************************************************************************************************************

<' How to Find Empty/Blank Log files in Active Log Space '>

	db2flsn -db <dbname> -lsnrange

	db2flsn -db <dbname> -lsnrange 4 ---> 4 is the log file name 

	db2flsn -db <dbname> -lsnrange -startlog 1 -endlog 4 -----> 1,4 are logfile names

********************************************************************************************************************
A query that looks into the catalogs for all table functions that start with 'MON_GET' or 'SNAP', etc., and which lists out both the input and output parameters (plus names & types, etc., for both)

db2 "select
substr(P.ROUTINENAME,1,48) as ROUTINENAME,
substr(P.SPECIFICNAME,1,48) as SPECIFICNAME,
case when P.ROWTYPE in ('B','O','P') then CHAR('IN',3) else CHAR('OUT',3) end as IN_OUT,
cast(p.ORDINAL as char(3)) as ORD,
substr(P.PARMNAME,1,40) as PARMNAME,
substr(P.TYPENAME,1,16) as TYPE
from sysibm.sysroutines r, sysibm.sysroutineparms p
where p.routineschema=r.routineschema
and p.routinename=r.routinename
and p.specificname=r.specificname
and r.function_type='T'
and substr(r.ROUTINENAME,1,4) in ('SNAP','MON_','ENV_','WLM_','COMP')
order by P.ROUTINESCHEMA,P.ROUTINENAME,P.SPECIFICNAME,IN_OUT,P.ORDINAL"

http://www.idug.org/p/bl/et/blogaid=270

END

****************************************************************************
--<" Performance Tuning: #performance #perf #query #querytuning #tuning "> 
****************************************************************************

BEGIN

Demoted I/O requests may lead to DB2 performance problems

https://www-304.ibm.com/support/docview.wss?uid=swg21469603


<' Identifying long running sql '> #longrun #performance #tuning 

	db2 "SELECT ELAPSED_TIME_MIN,SUBSTR(AUTHID,1,10) AS AUTH_ID, AGENT_ID,APPL_STATUS,SUBSTR(STMT_TEXT,1,100) AS SQL_TEXT FROM SYSIBMADM.LONG_RUNNING_SQL WHERE ELAPSED_TIME_MIN > 0 ORDER BY ELAPSED_TIME_MIN DESC with ur"

	db2 "select stmt_text, rows_read, rows_written, stmt_sorts, sort_overflows, num_executions, rows_read/num_executions avg_rows_per_exec from sysibmadm.snapdyn_sql order by rows_read desc fetch first 5 rows only with ur"

************************************************************************

<' To find  the read efficiency and rows read values of the queires that has been executed '> 

	PMR used # http://www.ibm.com/developerworks/data/library/techarticle/dm-1211packagecache/


		"WITH SUM_TAB (SUM_RR) AS (
		SELECT FLOAT(SUM(ROWS_READ))
		FROM TABLE(MON_GET_PKG_CACHE_STMT ( 'D', NULL, NULL, -2)) AS T)
		SELECT
		SUBSTR(STMT_TEXT,1,1500) AS STATEMENT,
		ROWS_READ,
		DECIMAL(100*(FLOAT(ROWS_READ)/SUM_TAB.SUM_RR),5,2) AS PCT_TOT_RR,
		ROWS_RETURNED,
		CASE
		WHEN ROWS_RETURNED > 0 THEN
		DECIMAL(FLOAT(ROWS_READ)/FLOAT(ROWS_RETURNED),10,2)
		ELSE -1
		END AS READ_EFFICIENCY,
		NUM_EXECUTIONS
		FROM TABLE(MON_GET_PKG_CACHE_STMT ( 'D', NULL, NULL, -2)) AS T, SUM_TAB
		ORDER BY READ_EFFICIENCY DESC FETCH FIRST 5 ROWS ONLY WITH UR; " 

************************************************************************

		" WITH SUM_TAB (SUM_RR) AS (
		SELECT FLOAT(SUM(ROWS_READ))
		FROM TABLE(MON_GET_PKG_CACHE_STMT ( 'D', NULL, NULL, -2)) AS T)
		SELECT
		SUBSTR(STMT_TEXT,1,1500) AS STATEMENT,
		ROWS_READ,
		DECIMAL(100*(FLOAT(ROWS_READ)/SUM_TAB.SUM_RR),5,2) AS PCT_TOT_RR,
		ROWS_RETURNED,
		CASE
		WHEN ROWS_RETURNED > 0 THEN
		DECIMAL(FLOAT(ROWS_READ)/FLOAT(ROWS_RETURNED),10,2)
		ELSE -1
		END AS READ_EFFICIENCY,
		NUM_EXECUTIONS
		FROM TABLE(MON_GET_PKG_CACHE_STMT ( 'D', NULL, NULL, -2)) AS T, SUM_TAB
		ORDER BY ROWS_READ DESC FETCH FIRST 5 ROWS ONLY WITH UR;"

****************************************************************************
<' Snapshot monitoring '>

	db2 get snapshot for all applications
	db2 list application show detail | grep Pend
	db2 get snapshot for locks on <dbname>
	db2 get snapshot for dynamic sql on <dbname>
	db2 get snapshot for application agentid <app-id> | more
	db2 get health snapshot for database on <dbname> 

*******************************************************************************

<' Forcing an application after getting confirmation from customer '>

	db2 "force applications <agentid> " OR db2 "force applications all" 

	db2 "force applications ('56')"


Looking at How Much Memory DB2 is Using: http://db2commerce.com/2012/11/20/looking-at-how-much-memory-db2-is-using/

END

********************************
--< MISC. TOOLS and COMMANDS =>
********************************

BEGIN

****************************************************************************
--<' DB2DIAG '>
	
	db2diag -gi "level=error" -H 1d
	db2diag -time yyyy-mm-dd-hh.mm.ss:YYYY-MM-DD-HH.MM.SS
	db2diag -level "Error,Severe" -H 1d | more  
	db2diag -rc <reason code>

' Show the Critical and Error messages in the last 24 hours: '

	db2 "SELECT TIMESTAMP, SUBSTR(MSG,1,400) AS MSG FROM SYSIBMADM.PDLOGMSGS_LAST24HOURS WHERE MSGSEVERITY IN ('C','E') ORDER BY TIMESTAMP DESC"

' Show the Critical and Error messages in the last 7 DAYS : '

	db2 "SELECT TIMESTAMP, APPL_ID, DBPARTITIONNUM, SUBSTR(MSG,1,400) AS MSG FROM TABLE ( PD_GET_LOG_MSGS( CURRENT_TIMESTAMP - 7 DAYS)) AS T WHERE INSTANCENAME = 'DB2' AND DBNAME = 'SAMPLE' AND MSGSEVERITY IN ('C','E')ORDER BY TIMESTAMP ASC"

****************************************************************************
--<' DB2DART '>

	' FAKE a BACKUP using db2dart '

		"db2dart <db> /CHST /WHAT DBBP OFF;"

' DB2dart on a table '

	db2dart <db> /t /tsi <tbspID> /oi <objectID> /scr n /rptnn <inspctBACKUPObj.rpt>
		above command used to chk the table on a tbspc.

'Lower the high-water mark for a given tablespace '

	db2dart sample /dhwm /tsi
	db2dart sample /lhwm /tsi 10  

	db2dart should never be run against a database that still has active connections.
	
' Lowering the High Water Mark of a Tablespace '

	"db2dart testdb /dhwm /tsi 4 
	db2dart testdb /lhwm /tsi 6 /np 0 "
		db2dart should never be run against a database that still has active connections. 

Refer <! http://www-01.ibm.com/support/docview.wss?uid=swg21006526> 

' Corruption '  

db2dart has an option to mark an index invalid and make it drop pending. You can mark a corrupt index invalid with db2dart /MI.
INDEXREC - DB cfg option will decide when to recreate the indexes. 

For example:

		db2dart <dbname> /MI /TSI 9 /OI 11076.
		-tsi tablespaceid -OI is objectID 


	https://www.ibm.com/developerworks/data/library/techarticle/dm-1208corruptiondb2/
	
***************************************************************************
--<' DB2CKLOG '>
To check the log is corrupted ot not - use db2cklog tool #check #logcheck

	db2cklog 3 TO 5
	db2cklog 2

to check the validity of the log files ranging from S0000000.LOG to S0000005.LOG in the /home/nrichers/tests directory, you issue the command 

	db2cklog 0 TO 5 ARCHLOGPATH /home/nrichers/tests
	db2cklog CHECK 3 ARCHLOGPATH tests

***************************************************************************
--<' DB2INSPECT '>

	db2 "inspect check database begin TBSPACEID 5 OBJECTID 5 results keep checkts.log"

	When the report completes , you’ll need to format the output with the db2inspf utility.

	To format all errors, warnings and summaries from the data file checkts.out, execute the following:

		db2inspf checkts.log checkts_read.txt -e -s -w

***************************************************************************
--<' DB2ADUTL Queries '>

	-–To see the taken backup wtih timestamp
		$ db2adutl query full db <db_name>

	-–To check whether the taken backup image is valid or not
		$ db2adutl verify full taken at ’20120628112641′ database ‘<db_name>’

	–-To restore/extract the backup image from TSM
		$ db2adutl extract full taken at ‘timestamp’ database xxxxx

	–To see who are all have the access for db2audtl query
		$ db2adutl queryaccess for all

	–To see all db’s backup from TSM
		$ db2adutl query

	-To extract archived logs from TSM
		$ db2adutl extract logs between {logfilename1} and {logfilename2} db {dbname}
****************************************************************************
--<' DB2CAT '>

Analyzes the contents of <'packed descriptors'> Given a database name and other qualifying information, this command will query the system catalogs for information and format the results 

A packed descriptor is a column within the system catalog tables which DB2 uses to identify the details of a database object. 
db2cat dumps the contents of the packed descriptors for tables and formats them in a readable form. 

This tool will show all the meta info about a table indepth. 

-> Verify the table pd for corruption:

	db2cat -d <db> -n <table> -s <schema> -v -o db2cat0.out  

->Verify all table pd for corruption: 

	db2cat -d <db> -n % -s % -v -o all.verify  

****************************************************************************
<'TO get detailed report to submit to PMR/ To find root cause of errors '> #PMR

	A. Start the trace with “db2trc on –f trace.dmp”
	B. Run the command/job to produce the error. (Note: It is recommended not to have anything else running on this machine when collecting the db2 trace. This will prevent the trace from getting to big. ) 
	C. Turn off the trace - "db2trc off"
	D. Format the trace - 
		"db2trc flw trace.dmp trace.flw" and 
		"db2trc fmt trace.dmp trace.fmt" and 
		"db2trc fmt -c trace.dmp trace_drda.fmtc"

	Once done collecting the trace you will need to send me .flw, .fmt, and .fmtc files for further review. Please note the DB2 trace can and may effect performance/resources on the machine its being ran on, if it is kept running for a long period of time.  

	db2support . -s -g

<'when you see the slowness in the database, you need to execute a db2fodc -perf as follows:'> #PMR

	db2fodc -db <dbname> -perf full

nohup db2fodc -hang full -db P8OB1PR -detect connections">=1" connstatus=Compiling triggercount="3" interval="30" iteration="4" sleeptime="30" &
the above command will initiate the db2fodc automatically when it detects compling state hungs while executing a query.


This will generate a db2fodc directory with all information from DB2 and OS as well. It collects db2pd, snapshots, stacks from DB2 and all information from the OS as well such as iostat and vmstats. Usually it takes about 5 to 10 minutes and it just collects information without impacting the system.
Thenn, after it finishes, you collect a db2support and send us for analysis:

	db2support . -d <dbname> -c -s -m
	
****************************************************************************
<' To delete the logs except active log '>
 
(Before the logs can be cleared, we need to know which ones are inactive as deleteing an active transaction log will crash DB2)

stop all the applications

	db2 get db cfg for db | grep -i log
check for the path and activeLogFileName.
and execute

	db2 "prune logfile prior to <activeLogFileName>"

	and start the applications.

<' Archive files/folders to TSM '>

	dsmc archive "/home/proj1/*.txt" ->>> Archive all files in the /home/proj1 directory with a file extension of .txt.

	db2 archive log for db <dbname> -> to archive manually to TSM

<' to stop the DB2 logger that is archiving the logs to the Tivoli Storage Manager Server? '> 


	db2pd -db <dbname> -fvp lam1 term

	where "lam1" is for LOGARCHMETH1 

***************************************************************************
END

************
--< HADR =>
************

BEGIN

<" Configuration parameters for database logging "> 

refer this link -> http://www.ibm.com/support/knowledgecenter/SSEPGG_10.1.0/com.ibm.db2.luw.admin.ha.doc/doc/r0006082.html


Starting 
	Standby:
		db2 start HADR on database DBNAME as STANDBY;

	Primary:
		db2 start HADR on database DBNAME as PRIMARY;

Stopping 

	PRIMARY:
		db2 stop HADR on database P8GCDQA;

	Standby:
		db2 deactivate db P8GCDQA;db2 stop HADR on database P8GCDQA;


db2 update db cfg for P8ICCQA using HADR_LOCAL_HOST NA341107-SAL HADR_LOCAL_SVC DB2_P8ICCQA_HADR_2 HADR_REMOTE_HOST NA341100-SAL HADR_REMOTE_SVC DB2_P8ICCQA_HADR_1

*****************************************************************************************

-- HADR isn’t “configured” properly - ERROR  

	we initated a restore with out removing the old Log files from the logstream. So while starting the HADR we are receiving 
	the below error. 

	ZRC=0x87800140=-2021654208=HDR_ZRC_CONFIGURATION_ERROR
	"One or both databases of the HADR pair is configured incorrectly"

	FUNCTION: DB2 UDB, High Availability Disaster Recovery, hdrEduEntry, probe:21150
	RETCODE : ZRC=0x87800148=-2021654200=HDR_ZRC_BAD_LOG
	"HADR standby found bad log"

	In this casee, at least the solution is simple. We deleted all the logs on the standby and thnen did the restore again, 
	and it worked. As much as I hate deleting log files – especially since they were in the active path – it was necessary. 

	reference -> http://db2commerce.com/2012/10/04/three-hadr-failures/

===============================================================================================================================

END

*********************************************
--< OSCOMMANDS..LUW..UNIX..LINUX..WINDOWS =>
*********************************************

BEGIN

<' To add user in a group '>

	useradd -G <group-name> username
	usermod -a -G <group-name> username   -> to add existing user to a existing group

' Changing owner and group of the file '

	chown <new_owner_name> <file_name>
	chgrp <new_group_name> <file_name>
	chown <new_owner_name>:<new_group_name> <file_name>

******************************************************
< ' About crontab in aix '>

<!  https://abcofaix.wordpress.com/tag/schedule-a-job-in-aix/ >

This post will discuss about the various commands used to schedule a job using crontab command.

Syntax:

X1 X2 X3 X4 X5 <command>

X1 represents time in minutes (0-59)
X2 represents time in hours (0-23)
X3 represents days (0-31)
X4 represents months (1-12)
X5 represents weekdays (0-6 where 0 stands for Sunday)

<EXAMPLE>
	Sep 1 12:30 AM is represented as:

	30 00 1 9 * <command>

# ***************************************************************
# Offline Database Backups
# 1. Every Tuesday @ 1:00 am EDT
# 2. Every Friday @ 1:00 am EDT
# ***************************************************************

	00 01 * * 2 /opt/db2/bin/backup_alldbs_offline_wrapper.shl > /dev/null
	00 01 * * 5 /opt/db2/bin/backup_alldbs_offline_wrapper.shl > /dev/null


******************************************************

<' Copy using SCP command '>

Set parameters in /etc/ssh/shd_config >> Permitroot login, passwordAuthentication and AllowTCPforwarding 

#add hosts in /etc/hosts

To copy a file from B to A while logged into B:

	scp /path/to/file username@a:/path/to/destination

<Example>
	scp /home/linges/DB2_Command_Various.txt lokesh@9.113.90.153:/home/lokesh

To copy a file from B to A while logged into A:

	scp username@b:/path/to/file /path/to/destination

************************************************
<' Network Commands '>

	1. ping 10.64.11.29

	2. telnet 10.64.11.29 50000 >> iff connection is refused thenn it means port is not opened

	3. traceroute camtpnw010nbfxa 50000

		<Example> output ------->traceroute 10.37.5.139 60000
		trying to get source for 10.37.5.139
		source should be 10.37.5.181
		traceroute to 10.37.5.139 (10.37.5.139) from 10.37.5.181 (10.37.5.181), 30 hops max
		outgoing MTU = 1500
		1 * * *
		2 * *

	4. nslookup camtpnw010nbfxa 
	
	5. netstat -an |grep -w 60000

	5. no -a | grep tcptr

	6. route add -host 10.37.5.139 10.37.5.181 -if en0 -iface   -> to route the servers (do this if you have interminent conection failure b/w servers)

	7. netstat -aAn|grep 50000 (this is an example) to see which app is using which port
		f1000e000258d3b8 tcp 0 0 192.168.1.114.58420 192.168.1.115.23 FIN_WAIT_1

	Now to remove the socket... to remove the particular app from the port use rmsock
	# rmsock f1000e000258d3b8 tcpcb
	socket 0x258d008 is removed. 
	
************************************************
< ' To see the size of RAM '>

	lsconf | grep Memory 
	getconf REAL_MEMORY

	svmon 

	oslevel -s -> to check OS version

-> to check whether an IBM® AIX® host is 32-bit or 64-bit capable :

	getconf KERNEL_BITMODE 
	getconf HARDWARE_BITMODE


	adinfo -v -> too check centrify version

	vmstat -w -t >>> to check memory

	<Example> vmstat 3 3 

<'To list applications installed in the OS '>

	lslpp -l | grep -i <application_mane>


<' How to see WWPN number for SAN storage '>

	lsdev -Cc adapter | grep fcs 
	lscfg -vl fcs0 (from above step) >>> where fcs0 is the fibre adapter number obtained from step 1 

	lscfg -vpl hdisk1 --> UID information prior u sud know which hdisk belongs to the required VG, on wich the lv sits & finally the FS sits

	<Example> ---> lscfg -vl fcs1(and so) 


<'To list the users who is using more Semaphores'>

	less ipcs.sra | awk ' { print $5 } ' | sort | uniq -c | sort -nr | head


<' About filesystem in Linux: '>

	Increase the Size of the Logical Volume:

	df -h, df -TH (to see the type of filesystem)

	fdisk -l to view the total hard disk(s) size and partitions on the disk

	pvs --> Physical Volume Show command
	lvs --> to show the logical volume information
	vgs --> Volume group info

	lvextend -L +6G <The.path.for.the.logical.volume.to.increase>

	mount and press ENTER to display the mounted file systems. From the output, we find that the <logical_volume> is using wch filesystem <xfs>. [[blkid /dev/sda1]] will also show UUID and type 
	To increase the file system to match that of the logical volume, we will use the xfs_growfs command if the filesystem uses xfs or resize2fs if the filesystem is ext4.

	<!--  http://www.tecmint.com/create-lvm-storage-in-linux/ --> to get complete knowledge on filesystem creation


<' How to run X11 using sshd x11 forwarding '> #X11 #xming #xclock #x11forwarding #xauth  


	1. Install X11 and Xserver application . eg: xming 

	2. Run Xserver application.  

	3. Enable X11 forwarding for the SSH daemon on Putty  

		Maximize the SSH tab and check on X11 Forwarding  

		Note Make sure not to add :  
		** X display location with <Other_machine_IP>  

	4. Connect via SSH port 22  

	5. Make sure all X11 file sets are installed correctly, they should be  
		installed by default with the AIX installation.  

		lslpp -L | grep X11  

		X11.adt.bitmaps 7.1.0.0 C F AIXwindows  
		Application  
		X11.adt.imake 7.1.0.0 C F AIXwindows  
		Application  
		X11.adt.include 7.1.4.0 C F AIXwindows  
		Application  
		X11.adt.lib 7.1.2.15 C F AIXwindows  
		Application  
		X11.apps.aixterm 7.1.4.0 C F AIXwindows aixterm  
		Application  
		X11.apps.clients 7.1.0.15 C F AIXwindows Client  
		Applications  
		X11.apps.config 7.1.3.0 C F AIXwindows  
		Configuration  
		X11.apps.custom 7.1.0.0 C F AIXwindows  
		Customizing Tool  
		X11.apps.msmit 7.1.2.15 C F AIXwindows msmit  
		Application  
		X11.apps.rte 7.1.4.0 C F AIXwindows Runtime  
		X11.apps.util 7.1.0.0 C F AIXwindows Utility  
		X11.apps.xdm 7.1.4.0 C F AIXwindows xdm  
		Application  
		X11.apps.xterm 7.1.4.0 C F AIXwindows xterm  
		Application  
		X11.base.common 7.1.0.0 C F AIXwindows Runtime 
		Common  
		X11.base.lib 7.1.4.0 C F AIXwindows Runtime  
		Libraries  
		X11.base.rte 7.1.4.0 C F AIXwindows Runtime  
		Environment  
		X11.base.smt 7.1.4.0 C F AIXwindows Runtime  
		Shared  
		X11.base.xpconfig 7.1.0.0 C F Xprint Configuration
		Files  
		X11.compat.lib.X11R6 7.1.4.0 C F AIXwindows X11R6  
		Compatibility  
		X11.compat.lib.X11R6_motif  
		7.1.3.0 C F AIXwindows X11R6  
		Motif 1.2 &  
		X11.fnt.coreX 7.1.0.0 C F AIXwindows X  
		Consortium Fonts  
		X11.fnt.defaultFonts 7.1.0.0 C F AIXwindows Default  
		Fonts  
		X11.fnt.iso1 7.1.0.0 C F AIXwindows Latin 1  
		Fonts  
		X11.fnt.iso_T1 7.1.0.0 C F AIXwindows Latin  
		Type1 Fonts  
		X11.loc.en_US.base.lib 7.1.0.0 C F AIXwindows Client  
		Locale  
		X11.loc.en_US.base.rte 7.1.0.0 C F AIXwindows Locale  
		X11.motif.lib 7.1.3.0 C F AIXwindows Motif  
		Libraries  
		X11.motif.mwm 7.1.1.0 C F AIXwindows Motif  
		Window  
		X11.msg.en_US.adt.imake 7.1.3.0 C F AIXwindows imake  
		Messages -  
		X11.msg.en_US.apps.aixterm  
		X11.msg.en_US.apps.clients  
		X11.msg.en_US.apps.config 7.1.3.0 C F AIXwindows Config  
		Apps Msgs -  
		X11.msg.en_US.apps.custom 7.1.3.0 C F AIXwindows Custom  
		Tool Msgs -  
		X11.msg.en_US.apps.rte 7.1.3.0 C F AIXwindows Runtime  
		Config Msgs  
		X11.msg.en_US.apps.xdm 7.1.3.0 C F AIXwindows xdm  
		Messages - U.S.  
		X11.msg.en_US.base.common 7.1.3.0 C F AIXwindows Common  
		Messages -  
		X11.msg.en_US.base.rte 7.1.3.0 C F AIXwindows Runtime  
		Env. Msgs -  
		X11.msg.en_US.motif.lib 7.1.3.0 C F AIXwindows Motif Lib.
		Msgs -  
		X11.msg.en_US.motif.mwm 7.1.3.0 C F AIX Motif Window Mgr
		Msgs -  
		X11.msg.en_US.vsm.rte 7.1.3.0 C F Visual Sys Mgmt.  
		Helps & Msgs  
		X11.samples.apps.clients 7.1.4.0 C F AIXwindows Sample X  
		Consortium  
		X11.samples.common 7.1.0.0 C F AIXwindows Imakefile
		Structure  
		X11.samples.lib.Core 7.1.4.0 C F AIXwindows Sample X  
		Consortium  
		X11.vsm.lib 7.1.0.0 C F Visual System  
		Managment  
		bos.rte.X11 7.1.0.0 C F AIXwindows Device  
		Support  
		devices.pci.02105e51.X11 7.1.1.15 C F AIXwindows Native  
		Display  
		devices.pci.14101b02.X11 7.1.1.15 C F AIXwindows GXT6500P  
		Graphics  
		devices.pci.14101c02.X11 7.1.1.15 C F AIXwindows GXT4500P  
		Graphics  
		devices.pci.14103302.X11 7.1.1.0 C F AIXwindows GXT135P  
		Graphics  
		devices.pci.14106e01.X11 7.1.1.15 C F AIXwindows GXT4000P  
		Graphics  
		devices.pci.14107001.X11 7.1.1.15 C F AIXwindows GXT6000P  
		Graphics  
		devices.pci.2b102725.X11 7.1.1.0 C F AIXwindows GXT145  
		Graphics  
		devices.serial.sb1.X11 7.1.0.0 C F AIXwindows 6094-030  
		Spaceball  
		devices.serial.tablet1.X11  

	6. Enable X11 forwarding for the SSH daemon on AIX:  

		cd /etc/ssh  
		vi sshd_config  
		Uncomment the entry:  
		#X11Forwarding no  
		The no indicates the default setting. Change it to yes  
		X11Forwarding yes  

	7. restart SSH daemon:  

		Stop and start the ssh daemon (sshd), which can be done even while  
		youre connected via ssh:  
		#stopsrc -s sshd  
		#startsrc -s sshd  

	8. check the DISPLAY and authentication value.  

		# echo $DISPLAY  
		DISPLAY=localhost:10  
		# xauth list  
		server/unix:10 MIT-MAGIC-COOKIE-1 6299564796e4cf089e38619a354cfdcc  

		Note: If you open more ssh sessions to one host, with the X11 forwarding
		turned on,  
		every session will have different offset number in the DISPLAY variable.
		The offset number is the one after a colon, e.g. 10 in the example  
		above.  

	9. Make sure that the LANG variable is set to en_US, if not change it.  

		# echo $LANG  
		en_US  

		** If it is EN_US  

		Run :  
		#export LANG=en_US  
		# echo $LANG  
		en_US  

	10. Run xclock to test.  

		#xclock  

***********************************************************************************************************************
END

******************************************
--< "Scripts (Linux) --- TIPS AND TRICKS ">
******************************************

BEGIN

<! http://honglus.blogspot.in/search/label/Tips%2FTricks  -> http://www.shellscript.sh/variables2.html >- USEFUL LINKS 
  Advanced Shell Bash Scripting Guide - http://tldp.org/LDP/abs/html/index.html

************************************


<' Pass password to a script '>

# ssh -q -o StrictHostKeyChecking=no vn01254@DWN10200Af "whoami;hostname;echo 'export PS1=\"\`hostname\`:\$USER:\${PWD}->\"' > new ; "

      http://stackoverflow.com/questions/233217/pass-password-to-su-sudo-ssh


Use expect - for automation 

'Sample scripts': #expect 

<- https://www.pantz.org/software/expect/expect_examples_and_tips.html ->
******************************************************************************************
#!/usr/bin/expect
set timeout 9
set username [lindex $argv 0]
set password [lindex $argv 1]
set hostname [lindex $argv 2]
log_user 0

if {[llength $argv] == 0} {
send_user "Usage: scriptname username \'password\' hostname\n"
exit 1
}

send_user "\n#####\n# $hostname\n#####\n"

spawn ssh -q -o StrictHostKeyChecking=no $username@$hostname

expect {
timeout { send_user "\nFailed to get password prompt\n"; exit 1 }
eof { send_user "\nSSH failure for $hostname\n"; exit 1 }
"*assword"
}

send "$password\r"

expect {
timeout { send_user "\nLogin failed. Password incorrect.\n"; exit 1}
"*\$ "
}

send_user "\nPassword is correct\n"
send "exit\r"
close

*******
#!/usr/bin/expect 
#login to local user and then sudo to admin user
spawn ssh -q -o StrictHostKeyChecking=no lm8@hpchdd2e
expect "*?assword*"
send "password0\r"
expect "*hpchdd2e*"
send "sudo su - cvdpdevp\r"
expect "?sudo? password for lm8:"
send "password\r"
set prompt_re {\$ >} # this is a regular expression that should match the
                     # *end* of you bash prompt. Alter it as required.
expect -re $prompt_re
interact

#####

#!/usr/bin/expect 
#sudo to admin user and stayin that session
set user [lindex $argv 0] 
spawn bash
expect "*hpchdd2e*"
send "sudo su - ${user}\r"
expect "?sudo? password for lm8:"
send "Lo0k@me0\r"
set prompt_re {\$ >}
expect -re $prompt_re
interact			 
******************************************************************************************

**********
<' SED '>*
**********

Sed - Detail Introduction  -> " http://www-rohan.sdsu.edu/doc/sed.html "

Replace conntent of a file in muliple servers using #sed and #ssh

Arrange file by its size 
du -hsx * | sort -rh | head -10

=======================
'To replace the password' 
=======================
servername=${1}
NbrOfS=`cat ${servername}|wc -l`
Slist=`cat ${servername}`
let y=1
echo "No of Servers in the list is $NbrOfS"
for SName in ${Slist} ; do
echo "Replacing in $SName"
ssh vn01254@$SName "whoami;hostname;sed "s/doctor33/doctor00/g" .profile"
let y=$y+1
done

=======================
'Add lines in .profile' 
=======================
servername=${1}
NbrOfS=`cat ${servername}|wc -l`
Slist=`cat ${servername}`
let y=1
echo "No of Servers in the list is $NbrOfS"
for SName in ${Slist} ; do
echo "changing .profile in $SName"
sleep 1
# ssh -q -o StrictHostKeyChecking=no vn01254@DWN10200Af "whoami;hostname;echo 'export PS1=\"\${USER}@\`hostname\`:${PWD}->\"' >> .profile ;"
let y=$y+1
done

**************************************************************************************
'SSH to execute commands in multiple remote server'

https://www.shellhacks.com/ssh-execute-remote-command-script-linux/

Examples:
	$ ssh USER@HOST 'COMMAND1; COMMAND2; COMMAND3'
	$ ssh USER@HOST 'COMMAND1 | COMMAND2 | COMMAND3'
	$ ssh root@192.168.1.1 'free -m | cat /proc/loadavg'
	$ ssh root@192.168.1.1 'bash -s' < script.sh
"Below provides ex of using remote execute a script that has arguments"	
	for Sname in `cat list.lst`; do
	server=`echo $Sname | awk -F "_" '{print $1}'`
	inst=`echo $Sname | awk -F "_" '{print $2}'`
	db=`echo $Sname | awk -F "_" '{print $3}'`
	ssh  -q -o StrictHostKeyChecking=no ${inst}@${server} 'ksh -s' -- < script.sh ${inst} ${db} >> /tmp/ling/new.log
	echo -- >> /tmp/ling/new.log
	sleep 1
	done


**************************************************************************************
<' Find and replace words in VI EDITOR: '>

:%s/WORD-To-Find-HERE/Replace-Word-Here/g
:%s/UNIX/Linux/gc >>> Find and Replace with Confirmation
:%s/\<UNIX\>/Linux/gc >>> Find whole words exactly matching 'UNIX' to 'Linux'; and ask for confirmation too
:%s/unix/Linux/gi >>> Find 'UNIX' (match UNIX, unix, UnIx, Unix and so on) and replace with 'Linux' (CASEE INSENSITIVE)
:%s/UNIX/bar/gI >>> Find each 'UNIX' and replace with 'bar' : Casee sensitive Find and Replace

To Replace In the Current Line Only: 
:s/UNIX/Linux/g

Replace All Lines Between line 100 and line 250
:{START-n},{ENDD-n}s/word1/word2/g
:100,200s/UNIX/Linux/g

**************************************************************************************
'Apply commands to list of tables in a text file'

1. Put the list of tables in a file named tab_list.txt
2. paste the below lines in another file (Change the commands as your requirement)

	TblSPCListFl=${1}
	NbrOfTBS=`cat ${TblSPCListFl}|wc -l`
	TBSlist=`cat ${TblSPCListFl}`

	let y=1
	for TBSName in ${TBSlist} ; do
	echo "select substr(tabname,1,30) as tabname,substr(tabschema,1,10) as schema,type,status from syscat.tables where tabname='${TBSName}';" >> tab_details.sql
	let y=$y+1
	done

3. And execute the script by ./{script_name} tab_list.txt 
4. Now we can execute the .sql file (using db2 -tvf option) which is created by the script.

**************************************************************************************
< "How to Find Which DB2 Thread is consuming High CPU " > #db2thread #highcpu #performance

	ps -ef | grep -i db2sysc >> get PID of db2sysc 
	top -Hp <db2syscPID> >> to display individual threads, look for %CPU and %MEM.... but thread names not avaible in this command
	ps -Lp <db2syscPID> -o pid,ppid,pcpu,pmem,lwp >> same kind of info like the above command available here too

" db2pd -edus " >> the individual thread name can be obtained by this command

**************************************************************************************
<" How to add quotes for a line using sed and awk">
	->cat number | awk '{printf("\"%s\"\n", $0);}'
	"1"
	"2"
	"3"
	"4"
	"5"
	"6"
	"7"
	"8"
	"9"
	"0"
	->cat number | awk '{printf("\"%s\"\n", $0);}' | paste -sd, -
	"1","2","3","4","5","6","7","8","9","0"

#	->cat number | sed s/^/\'/g | sed s/$/\'/g | paste -sd, -

#''	-'>cat number | sed 's/^/"/;s/$/"/'

<"Remove junk characters from file">:

	tr -cd '\11\12\15\40-\176' < input.sql > output.sql

'**************************************************************************************
'Generate timestamp to attach to a output file name

	==> db2 -x "select substr(REPLACE(CHAR(DATE(current date),iso),'-','')||REPLACE(VARCHAR(current time),':',''),1,14) from sysibm.sysdummy1"
	20161023151147

	==> dateit=`date +"%C%y%m%d_%H%M"`
	20161024_0054
	==>select 'ENDING SCRIPT AT: ' || current timestamp(0) from sysibm.sysdummy1
		1
	-------------------------------------
	ENDING SCRIPT AT: 2018-07-03-07.28.21

	
Loops: 
	# make sure it doesnot run "forever"
	let i=1
	while [ i -le ${iterations} ]
	do
	echo "${i} / ${iterations}"  
	echo `date +"%C%y%m%d_%H%M"`
	../Run_Iteration_SQL_SNAPS.shl ${DBName}
	sleep ${cmd_interval}
	let i=$i+1
	done

**************************************************************************************
'Delete all files in /opt/db2/logs > 90 days old & owned by authid running script '


	find /opt/db2/logs -mtime +90 -type f -user ${USER} -exec rm {} \;
	
	To list files based on the size:
	find /homeudb  -xdev -size +100 -exec ls -lrt {} \;  2>/dev/null | sort -nrk 5 | head -100

**************************************************************************************
'File Operations'

	-s Checks if file has size greater than 0; if yes, then condition becomes true.
	-f file exists and is not a directory
	-d directory exists
	-e Checks if file or directory exists 
	-x file is executable
	-w file is writable
	-r file is readable
	-n
	-z
'Positional Parameters' $0, $1, $2, etc
	
	$# - Number of command-line arguments or positional parameters
	$* - All of the positional parameters, seen as a single word : Note "$*" must be quoted.
	$@ - This means, that each parameter in the argument list is seen as a separate word.
	
	Other Spl parameters: 
	$! - PID (process ID) of last job run in background
	






'Change the Timestamp format to yyyy:mm:dd hh:mm:ss format in excel'

	=TEXT(DATE(LEFT(H2,4),MID(H2,5,2),MID(H2,7,2))+TIME(MID(H2,9,2),MID(H2,11,2),MID(H2,13,2)),"yyyy-mm-dd-hh.mm.ss")
	=--TEXT(H2,"0000\-00\-00\ 00\:00\:00")
	where H2 is the cell in excel that has the timestamp value. 
**************************************************************************************
'Batch Scripting'

To find list of instance and local dbs and to get some general info.

	@echo off
	set dtm=%date:~-4,4%%date:~-10,2%%date:~-7,2%_%time:~0,2%%time:~3,2%%time:~6,2%

	echo %COMPUTERNAME%
	echo.
	ver 
	echo.
	db2ilist > instance.txt
	echo.

	for /F "tokens=1" %%A in (instance.txt) do ( 
	set db2instance=%%A
	db2level 
	db2licm -l 
	db2 get dbm cfg 
	db2cfexp dbm_%%A_%dtm%.cfg
	db2set -all 
	) > info_%%A_%dtm%.txt

	db2 list db directory > dbdir_out.txt 

	setlocal EnableDelayedExpansion
	set lastLine=0
	< dbdir_out.txt (for /F "delims=:" %%a in (
				  'findstr /N /C:"Indirect" dbdir_out.txt') do (
	   set /A skip=%%a-lastLine-5, lastLine=%%a+1
	   for /L %%i in (1,1,!skip!) do set /P line=
	   for /L %%i in (1,1,6) do set /P "line=!line!" & echo/
	   echo/
	)) > db_list.txt 

	for /F "tokens=2 delims==" %%A in ('findstr /C:"alias" db_list.txt') do (
	echo %%A
	db2 get db cfg for %%A > db_cfg_%%A_%dtm%.out
	db2look -d %%A -e -o db2look_%%A_%dtm%.txt -l -xd
	) > database_info_%dtm%.txt

	echo.
**************************************************************************************
END



**************************************************************************************
Netezza:

Query will provide the database backup time (Full / Differential / User backup) for each database along with the backup start and finish time. Query will not display any data for failed database backup attempts

	select DBName, OPTYPE, starttime, lastupdate, (lastupdate-starttime)/60 as DurationInMinutes from _v_backup_history where status='COMPLETED' and DBNAME is NOT NULL and StartTime>'2012-10-01 00:00:00' order by DBName, starttime;
